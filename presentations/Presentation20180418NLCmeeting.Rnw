\documentclass[10pt,fleqn]{beamer}
 
\usepackage{lmodern}
\usepackage{knmiBeamer}
\usepackage{multirow}
\usepackage[skins]{tcolorbox}

\Engelstrue     % For English slides 
\renewcommand{\titleFigure}{../figure/fogCover.jpg}

\usepackage{tikz}
\usepackage{verbatim}
\usetikzlibrary{arrows, shapes}

% ---------------
% Graphics folder
% ---------------
\graphicspath{{../figure/}}


\title[Automatic fog detection]{Automatic fog detection using camera images: project overview}
%\Subtitletrue
%\subtitle{abc}
\date{April 18, 2018}
\author[Pagani, Noteboom and Wauben]{\scriptsize{Pagani, Noteboom and Wauben}}

\begin{document}
\tikzstyle{every picture}+=[remember picture]


\begin{frame}
 \titlepage
 \begin{textblock*}{5cm}(7cm,8.4cm)
 \begin{tiny}
 \textit{RDWD NLC meeting -- April 18, 2018}
 \end{tiny}
 \end{textblock*}
\end{frame}


% \begin{frame}{Outline}
% \begin{itemize}
%   \item Motivation for Fog research
%    \item Purpose
%    \item Sensors vs. cameras
%    \item Data sets
%    \item Neural Networks
%    \item Results
%    \item Next steps
% \end{itemize}
% \end{frame}



<<Libraries, include=FALSE>>=
library(data.table)
library(imager)
library(visDec)
library(ggplot2)
library(rpart)
library(rattle)
library(rgdal)
library(ggmap)

library(DBI)
library(jsonlite)
library(data.table)
library(caret)
library(darch)
library(latex2exp)


knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
knitr::opts_chunk$set(error = TRUE)

#setwd("~/development/fogDec/")

@






<<confusionDraw, echo=FALSE, include=FALSE>>=
draw_confusion_matrix_binary <- function(cm) {

     layout(matrix(c(1,1,2)))
     par(mar=c(2,2,2,2))
     plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
     title('CONFUSION MATRIX', cex.main=2)

     # create the matrix
     rect(150, 430, 240, 370, col='#3F97D0')
     text(195, 435, 'FALSE', cex=1.2)
     rect(250, 430, 340, 370, col='#F7AD50')
     text(295, 435, 'TRUE', cex=1.2)
     text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
     text(245, 450, 'Actual', cex=1.3, font=2)
     rect(150, 305, 240, 365, col='#F7AD50')
     rect(250, 305, 340, 365, col='#3F97D0')
     text(140, 400, 'FALSE', cex=1.2, srt=90)
     text(140, 335, 'TRUE', cex=1.2, srt=90)

     # add in the cm results
     res <- as.numeric(cm$table)
     text(195, 400, res[1], cex=1.6, font=2, col='white')
     text(195, 335, res[2], cex=1.6, font=2, col='white')
     text(295, 400, res[3], cex=1.6, font=2, col='white')
     text(295, 335, res[4], cex=1.6, font=2, col='white')

     # add in the specifics
     plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
     #text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
     #text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
     #text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
     #text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
     text(10, 85, names(cm$byClass[5]), cex=1.4, font=2)
     text(10, 65, round(as.numeric(cm$byClass[5]), 3), cex=1.4)
     text(30, 85, names(cm$byClass[6]), cex=1.4, font=2)
     text(30, 65, round(as.numeric(cm$byClass[6]), 3), cex=1.4)
     text(50, 85, names(cm$byClass[7]), cex=1.4, font=2)
     text(50, 65, round(as.numeric(cm$byClass[7]), 3), cex=1.4)

     # add in the accuracy information
     text(80, 85, names(cm$overall[1]), cex=1.4, font=2)
     text(80, 65, round(as.numeric(cm$overall[1]), 3), cex=1.4)
     #text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
     #text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
   }
@









<<confusionDrawExplanation, echo=FALSE, include=FALSE>>=
draw_confusion_matrix_binary_explanation <- function() {

     layout(matrix(c(1,1,2)))
     par(mar=c(2,2,2,2))
     plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
     title('CONFUSION MATRIX', cex.main=2)

     # create the matrix
     rect(150, 430, 240, 370, col='#3F97D0')
     text(195, 435, 'FALSE', cex=1.2)
     rect(250, 430, 340, 370, col='#F7AD50')
     text(295, 435, 'TRUE', cex=1.2)
     text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
     text(245, 450, 'Actual', cex=1.3, font=2)
     rect(150, 305, 240, 365, col='#F7AD50')
     rect(250, 305, 340, 365, col='#3F97D0')
     text(140, 400, 'FALSE', cex=1.2, srt=90)
     text(140, 335, 'TRUE', cex=1.2, srt=90)

     # add in the cm results
     #res <- as.numeric(cm$table)
     text(195, 400, "TN", cex=1.6, font=2, col='white')
     text(195, 335, "FP", cex=1.6, font=2, col='white')
     text(295, 400, "FN", cex=1.6, font=2, col='white')
     text(295, 335, "TP", cex=1.6, font=2, col='white')

     # add in the specifics
     plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
     text(10, 85, "Precision", cex=1.4, font=2)
     text(10, 50, TeX("\\frac{TP}{TP+FP}$"), cex=1.4)
     text(30, 85, "Recall", cex=1.4, font=2)
     text(30, 50, TeX("\\frac{TP}{TP+FN}$"), cex=1.4)
     text(55, 85, "F1 Score", cex=1.4, font=2)
     text(55, 50, TeX("\\frac{$2\\cdot$Precision$\\cdot$Recall}{Precision+Recall}"), cex=1.4)


     # add in the accuracy information
     text(80, 85, "Accuracy", cex=1.4, font=2)
     text(80, 50, TeX("\\frac{TP+TN}{TP+TN+FP+FN}$"), cex=1.4)
     #text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
     #text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
   }
@














\begin{frame}{Fog as hazard}
 \begin{textblock*}{5cm}(7.4cm,2.4cm)
  \includegraphics[width=5cm]{Accident.jpeg}
 \end{textblock*}
 \begin{textblock*}{5cm}(7.4cm,5.5cm)
  \includegraphics[width=5cm]{airplane.jpg}
 \end{textblock*}

\begin{textblock*}{7cm}(0.2cm,4.25cm)
\begin{itemize}
  \item Substantial impact on air, marine, and road traffic
  %\item Loss of life comparable to that of tornadoes or even winter storms\footnote{Gultepe, I. et al. (2007): Fog research: A review of past achievements and future perspectives. \emph{Pure and Applied Geophysics}, \textbf{164}, 1121--1159.}
  \item Forms and dissipates suddenly
  %\item Often  local phenomenon
  \item Not easy to accurately forecast

 \end{itemize}
  \end{textblock*}
\end{frame}



\begin{frame}{Goal \& Scope}
\begin{itemize}
\item \textbf{Purpose:} use cameras to identify fog conditions to issue safety warnings
\item \textbf{Value:}
\begin{itemize}
\item \textit{Society: }
\begin{itemize}
\item human lives
\item economic
\end{itemize}
\item \textit{KNMI:}
\begin{itemize}
\item more fog observations
\item improve modeling/fog predictions
\end{itemize}

\end{itemize}
\item \textbf{Scope:} daylight fog identification from static and moving cameras using image analysis

\end{itemize}
\end{frame}




\begin{frame}{Traditional sensors vs. traffic cameras}
%\begin{itemize}
% \item Satellites are not pointing to NL 24/7
%   \item But maybe other ubiquitous ``sensors'' can be used e.g., traffic cameras
%   \end{itemize}
   \begin{textblock*}{5cm}(0.5cm,4.0cm)
  \includegraphics[width=4cm]{fogSat.jpg}
 \end{textblock*}
 \begin{textblock*}{5cm}(4.95cm,4.0cm)
  \includegraphics[width=3cm]{SensorPlacement.png}
 \end{textblock*}
 \begin{textblock*}{5cm}(8.4cm,4cm)
  \includegraphics[width=4cm]{CameraPlacement.jpg}
 \end{textblock*}
\end{frame}





<< ExamplePictures, include=FALSE, cache=FALSE>>=
path <- system.file("../extdata/Meetterrein", package="visDec")
filenames <- list.files(path,
                        pattern=glob2rx("Meetterrein_201510*.jpg"),
                        full.names=TRUE)
@


\begin{frame}{Approach: Big Data and Machine Learning}
\begin{textblock*}{12cm}(0.2cm,2.2cm)
\begin{itemize}
\begin{small}
\item Use big amount of data (i.e., images) to train models that can discriminate different (i.e., fog/non-fog) conditions.

\item Machine learning is the systematic study of algorithms and systems that improve
their knowledge or performance with experience.
\end{small}
\end{itemize}
\end{textblock*}
\begin{textblock*}{12cm}(0.2cm,3.75cm)
\begin{center}
\includegraphics[width=7cm]{figreML.png}
\end{center}
\end{textblock*}

\end{frame}





\begin{frame}{Machine learning approach: \textit{Features} extracted from images}
\begin{itemize}
\begin{footnotesize}
\item{Mean Edges: for finding the boundaries of objects within images. It works by detecting discontinuities in the image (e.g., foreground and background elements).}
\item{Mean Brightness: perception of a source of radiating/reflecting light.}
\item{Mean Saturation: is a measure of the purity of the color. The purest (most saturated) color is achieved by using just one wavelength, less pure come from a combination at different wavelengths.}
\item{Mean HUE: perception of a source of being similar to one of the perceived colors: red, yellow, green, and blue, or to a combination of two of them.}
\item{Fractal Dimension: self similarity in filling space.}
\item{Transmission smoothness: transmission of the darkchannel of the image (smoothed indicator).}
\item{Transmission changepoint: horizontal point where the transmission of the dark channel is subject to change.}
\end{footnotesize}
\end{itemize}
\end{frame}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\begin{frame}{Machine learning approach}
\vspace*{-5mm}
Example elaboration and feature: edge detection
<<LandmarkPlotClear, cache=TRUE, echo=FALSE, fig.height=4.2, fig.width=8.4>>=
im <- subim(load.image("../figure/Meetterrein_20150703_0320.jpg"), y > 16)


old_par <- par(mfrow=c(1,2))
plot(im)
#DetectEdges(im) %>% plot

#im <- subim(load.image(filenames[49]), y > 16)
#plot(im)
DetectEdges(im) %>% threshold(thr="98%") %>% plot()
par(old_par)
@
 \begin{textblock*}{10cm}(1.5cm,8cm)
  Consider the mean number of edges in the picture as feature.
 \end{textblock*}
\end{frame}





\begin{frame}{Machine learning: De Bilt classification tree} 
\scriptsize{keys for reading a node:\\
 fraction of fog cases in the node/sub-tree\\
 \# of cases  \textemdash \% of total cases}
 
<<Classification, include=FALSE>>=
load("../results/deBiltResults2015.RData")
imageSummary[, dayIsEven := mday(dateOnly) %% 2]
train <- imageSummary[, .(dateTime, MOR, meanEdge, changePoint, meanBrightness)]
train <- na.omit(train)
train[, foggy := MOR < 250]
fogTree <- rpart(foggy ~ meanEdge + changePoint + meanBrightness, train , control = rpart.control(cp = 0.019))
pred <- predict(fogTree, train, method="class")
train[, pred := pred]
@
<<ClassificationTree, echo=FALSE, fig.height=4>>=
fancyRpartPlot(fogTree, sub="")
@
% keys for reading a node:
% fraction of fog cases in the node/sub-tree
% # of cases
% \% of total cases
\end{frame}


<<resultsDeBilt, include=FALSE, warning=FALSE>>=
dbConfig <- fromJSON("../config.json")



con <- dbConnect(RPostgreSQL::PostgreSQL(),
                 dbname = "FOGDB",
                 host = dbConfig[["host"]], port = 9418,
                 user = dbConfig[["user"]], password = dbConfig[["pw"]])



#Get meteo conditions for De Bilt
tableMeteo <- dbGetQuery(con, "SELECT * from meteo_features_stations
                                  WHERE location_id =1;")

#Get features for De Bilt images

tableFeatures <- dbGetQuery(con, "SELECT * from image_features
                                  WHERE camera_id =1;")


tableMeteo <- data.table(tableMeteo)
tableMeteo[, foggy := mor_visibility < 250]


tableFeatures <- data.table(tableFeatures)

setkey(tableFeatures,timestamp)

setkey(tableMeteo,timestamp)




fullTable <- tableFeatures[tableMeteo,]
train <- fullTable[year(timestamp)==2016,]
test <- fullTable[year(timestamp)<2016,]

train<-train[is.na(foggy)==FALSE]
train[,foggy:= as.factor(foggy)]
trainDB<-dim(train)[1]


test<-test[is.na(foggy)==FALSE]
test[,foggy:=as.factor(foggy)]
testDB<-dim(test)[1]



tree<-rpart(foggy~mean_edge+change_point+smoothness+fractal_dim+mean_hue+mean_saturation+mean_brightness, data=train)

#rf <- train(foggy~mean_edge+change_point+smoothness+fractal_dim+mean_hue+mean_saturation+mean_brightness, data=train, method="rf",na.action=na.exclude)

prova<-predict(tree, newdata = test, method ="class")
prova<-data.frame(prova)
matDB<-confusionMatrix(ifelse(prova$TRUE.>0.3, TRUE, FALSE), test$foggy,mode = "prec_recall", positive = "TRUE")

confMatDeBilt<-matDB
#$table
@


<<resultsCabauw, include=FALSE, warning=FALSE>>=
#Get meteo conditions for Cabauw

tableMeteo <- dbGetQuery(con, "SELECT * from meteo_features_stations
                                  WHERE location_id =3;")

#Get features for Cabauw images

tableFeatures <- dbGetQuery(con, "SELECT * from image_features
                                  WHERE camera_id =3;")


dbDisconnect(con)


tableMeteo <- data.table(tableMeteo)
tableMeteo[, foggy := mor_visibility < 250]


tableFeatures <- data.table(tableFeatures)

setkey(tableFeatures,timestamp)

setkey(tableMeteo,timestamp)




fullTable <- tableFeatures[tableMeteo,]
train <- fullTable[year(timestamp)==2017,]
test <- fullTable[year(timestamp)==2016,]

train<-train[is.na(foggy)==FALSE]
train[,foggy:= as.factor(foggy)]
trainCab<-dim(train)[1]


test<-test[is.na(foggy)==FALSE]
test[,foggy:=as.factor(foggy)]
testCab<-dim(test)[1]



tree<-rpart(foggy~mean_edge+change_point+smoothness+fractal_dim+mean_hue+mean_saturation+mean_brightness, data=train)

#rf <- train(foggy~mean_edge+change_point+smoothness+fractal_dim+mean_hue+mean_saturation+mean_brightness, data=train, method="rf",na.action=na.exclude)

prova<-predict(tree, newdata = test, method ="class")
prova<-data.frame(prova)
matCab<-confusionMatrix(ifelse(prova$TRUE.>0.3, TRUE, FALSE), test$foggy,mode = "prec_recall", positive = "TRUE")

confMatCabauw<-matCab
#$table

@



\begin{frame}{Evaluation of performance}
\begin{textblock*}{5.3cm}(0.2cm,2.75cm)
\begin{itemize}
\item Accuracy can be misleading especially in unbalanced datasets like this one.
\item Better to use:
\begin{itemize}
\item Precision: fraction of items selected that are relevant (correct) ($Prec=\frac{TP}{TP+FP}$)
\item Recall: fraction of items correctly selected on all the relevant items  ($Rec=\frac{TP}{TP+FN}$)
\item F1 Score: harmonic mean of precision and recall
\end{itemize}
\end{itemize}
\end{textblock*}
\begin{textblock*}{7cm}(5.5cm,3.75cm)
 <<confusionExplanation, echo=FALSE, fig.height=5, fig.width=8>>=
draw_confusion_matrix_binary_explanation()
@
\end{textblock*}
\end{frame}




\begin{frame}{Results:}
\begin{textblock*}{5cm}(0.5cm,2.5cm)
De Bilt camera:
%\begin{small}
%<<echo=FALSE>>=
%kable(confMatDeBilt)
%@
%<<echo=FALSE>>=
%kable(matDB$byClass[c(5,6,11)])
%@
<<echo=FALSE>>=
draw_confusion_matrix_binary(confMatDeBilt)
@

%\end{small}
\vspace{0.2cm}
Train set (year 2016): \Sexpr{trainDB}\\
Test set (6-12/2015): \Sexpr{testDB}\\
\end{textblock*}

\begin{textblock*}{5cm}(7.0cm,2.5cm) 
Cabauw camera:
<<echo=FALSE>>=
draw_confusion_matrix_binary(confMatCabauw)
@
\vspace{0.2cm}
Train set (year 2017): \Sexpr{trainCab}\\
Test set (10-12/2016): \Sexpr{testCab}\\
\end{textblock*}

\end{frame}



\begin{frame}{Twente KNMI station}\centering
%The situation in Twente is different for two reasons, the wide angle of the
%camera makes the horizontal averaging of the transmission rate less appropriate.
%Moreover, even on a clear day there are only a few edges in the image (which are
%mostly very close to the camera, i.e. from the equipment of the automatic 
%weather station). Nevertheless, it was quite simple to detect failures of the 
%visibility sensor using the two described features, such as during the afternoon
%of August 23 2015, where the sensor consistently gave $MOR < 250$, although the 
%image is very clear.
 \includegraphics[width=5cm]{EHTW_201508231400.jpg}
 \begin{itemize}
  \item fish-eye lens
  \item only a few edges in the range of 50--250\,m
  \item fully unprotected camera
 \end{itemize}
\end{frame}




\begin{frame}{Twente: weather (un)protection}%\centering
\begin{columns}
\column{0.2\textwidth}
\includegraphics[height=2cm]{wideCamera}

\column{0.8\textwidth}
\includegraphics[height=3cm]{../inst/extdata/cornerCasesTwente/EHTW_201506280400.jpg} \\
\includegraphics[height=3cm]{../inst/extdata/cornerCasesTwente/EHTW_201510060700.jpg} \\

\end{columns}
\begin{textblock*}{5cm}(6.2cm,3.85cm)
Ice on the camera enclosure\\
\vspace{2.7cm}
Water drops on the camera enclosure
\end{textblock*}



\end{frame}


























\begin{frame}{Project phase with RWS (since Jan 2017)}
\begin{itemize}
\item KNMI-RWS collaboration: partner to address a high-impact societal issue
\item RWS: 
\begin{itemize}
\item test new/innovative solution for mobility problems
\item more automatic warnings
\item more coverage than manual operators
\end{itemize}
\item KNMI: 
\begin{itemize}
\item have more data
\item test/improve ML models
\item deal with static and moving cameras of RWS domain
\item re-size the approach to deal with more data feeds
\end{itemize}
\end{itemize}
\end{frame}
% 
\begin{frame}{More data sets}
\begin{columns}
\column{0.6\textwidth}
\begin{itemize}
\item More datasets have been hunted ;-)
\item Let's refrain from discussing privacy issues, please!

\item Datasets:
\begin{itemize}
\item 4 Dutch airports: 7 cameras
\item 160 cameras along A15-A16-A4-A5-A1-A9-A50-A12-A27-A2 NL highways
\item 37 cameras along M90 Scottish motorway (test purposes)
\item 24 cameras Port of Rotterdam (still in contact to get them)
\end{itemize}
\item image sampling every 10 minutes
\item $\pm$ 7 million images archived
\item $\pm$ 1.5 million labeled
\end{itemize}
\column{0.4\textwidth}
   \includegraphics[width=4.5cm]{schiphol.jpg}
   \vspace*{0.2cm}
  \includegraphics[width=4.5cm]{camerasRWS.png}
\end{columns}

\end{frame}



% \begin{frame}{Data sets available}
% \begin{columns}
% \column{0.6\textwidth}
% \begin{itemize}
% \item 6 KNMI stations: 10 cameras (since 04/2016)
% \item 160 cameras along Dutch highways (since 07/2018)
% \item image sampling every 10 minutes
% \item $\pm$ 7 million images archived
% \item $\pm$ 1.5 million labeled
% \end{itemize}
% \column{0.4\textwidth}
%    \includegraphics[width=4.5cm]{schiphol.jpg}
%    \vspace*{0.2cm}
%   \includegraphics[width=4.5cm]{camerasRWS.png}
% \end{columns}
% 
% \end{frame}





\begin{frame}{Scraping the web for GPS coordinates}
\begin{textblock*}{9cm}(0.2cm,2cm)
\begin{center}
\begin{itemize}
\item RWS has a different coordinate system: highway+hectometre
\item We consider LAT-LON locations for cameras
\item GPS locations provided by RWS just 10 out of 160
\item Had to find a smart, fast, and easy way to get GPS coordinates of highways+hectometres
\item Web scraping becomes handy!
\item Website hmpaal.nl e.g., \tiny \url{http://www.hmpaal.nl/hectometer/A2/77.6/}
\normalsize
\item Python script that scrapes the GPS coordinates of highways+hectometres
\item Random cross-check with Google streetview
\item For the highways+hectometres not available: \underline{time-consuming} search via Google streetview (+-10/12 cases)
\end{itemize}
\end{center}
\end{textblock*}

\begin{textblock*}{6cm}(9cm,2.5cm)
\includegraphics[width=3.5cm]{webScraping.png}
\vspace{0.3cm}
\includegraphics[width=3.5cm]{hmPaal.PNG}
\end{textblock*}
\end{frame}




% 
\begin{frame}{From 1-camera analysis to a general solution}
\begin{itemize}
\item Thinking to a solution that can handle +100 cameras with:
\begin{itemize}
\item Centralized and persistent picture archiving
\item Archiving fault warning
\item Metadata extraction and storage at archival time
\item Ease of metadata and metrics access for faster analysis/modeling
\end{itemize}
\end{itemize}
\end{frame}
% 
\begin{frame}{Generic image archiving architecture implemented}

\includegraphics[width=10.75cm]{archiverArchitecture.png}

\end{frame}


\begin{frame}{DB design to archive metadata and image features computation}
Having the DB right is also important to streamline the analysis process down the road
\begin{center}
\includegraphics[width=8cm]{FogDBv7.png}
\end{center}
\end{frame}
% 
\begin{frame}{Flow for feature computation an ML model}
\begin{center}
\vspace*{-1cm}
\includegraphics[width=8cm]{computationFlow.png}
\end{center}


\begin{textblock*}{8cm}(6cm,7.5cm)
\begin{itemize}
   \item No more loose csv files with meteo
   \item No more loose rds files with feature computation
   \end{itemize}
 \end{textblock*}
\end{frame}




















\begin{frame}{Approach: Neural Network (in a nutshell)}
\begin{textblock*}{8cm}(0.5cm,3cm)
\begin{itemize}
\item Inspired by the functioning and firing of neurons in the brain
\item Allows the fitting of complex non-linear classification tasks
\item Works good with many input e.g., high order interaction terms
%would explode (e.g., 25x25px gray-scale image and we want quadratic interaction terms requires 3 millions features)
\item Training the network and tune the performance takes long time
\item Activation function can be customized (usually sigmoid-like function)
\end{itemize}
\end{textblock*}
\begin{textblock*}{8cm}(6.5cm,3cm)
\begin{center}
\includegraphics[width=3cm]{nnet.png}\\
\includegraphics[width=3cm]{artificial.jpg}
\end{center}
\end{textblock*}
\end{frame}


\begin{frame}{Why Neural Networks?}
\begin{textblock*}{9.5cm}(0.5cm,3.2cm)
\begin{itemize}
\item Used proficiently in image processing and image classification
\item More general method of fog detection than our previous attempt with decision trees and image features
\item Sceneries are too different also for the same camera (e.g., zoom)
\item Features are each pixel (of each of the RGB layers)
%\item Use a deep neural network (InputL:2352,L1:800,L2:500,L3:100,L5:10,OutputL:2) to fit the model
\end{itemize}
\end{textblock*}
\begin{textblock*}{8cm}(7.5cm,2.2cm)
\begin{center}
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170801_0502.jpg}\\
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1232.jpg}\\
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1242.jpg}
\end{center}
\end{textblock*}
\end{frame}






<<NN highways, echo=FALSE, include=FALSE>>=
#results for presentation

darch1<-readRDS("~/development/fogNNmodels/NNmodelTrainedWithStationCouplingEGU.RDS")
dataMatTrain<-readRDS("~/development/fogNNmodels/trainingDataMatEGU.RDS")
dataMatTest<-readRDS("~/development/fogNNmodels/testingDataMatEGU.RDS")

testing<-readRDS("~/development/fogNNmodels/testingDataLabelsEGU.RDS")
training<-readRDS("~/development/fogNNmodels/trainingDataLabelsEGU.RDS")

filesTest<-readRDS("~/development/fogNNmodels/filenamesTestEGU.RDS")
files<-readRDS("~/development/fogNNmodels/trainingFileNamesEGU.RDS")

predictedRWS<-predict(darch1,dataMatTrain, type = "bin")
predictedRWS<-data.table(predictedRWS)
predictedRWS[,fog:=V2>0]
predictedRWS[,file:=files]

confusion<-data.table(predicted=predictedRWS$fog,fogSensor=training$foggy)

#table(confusion$predicted,confusion$fog)

confMatrixTraining<-confusionMatrix(confusion$predicted,confusion$fog, mode = "prec_recall", positive = "TRUE")
@


\begin{frame}{Training and Test sets}
\begin{textblock*}{9.5cm}(0.5cm,3.5cm)
\begin{itemize}
\item Labels: from forward scatter visibility sensor that provides mteorological optical range (MOR)
\item Fog considered if visibility is $\leq$ 250m
\item Point of concern: labels for highway cameras are given by a KNMI station in a radius of 7.5km
\item Balanced training set: $\pm$ \Sexpr{round(sum(training$foggy/100))*100} random fog and $\pm$ \Sexpr{round(sum(training$foggy==FALSE)/100)*100} non-fog images from \Sexpr{length(unique(training$camera_id))} cameras
\item Test set: $\pm$ \Sexpr{round(sum(testing$foggy)/100)*100} fog and  $\pm$ \Sexpr{round(sum(testing$foggy==FALSE)/100)*100} non-fog images
\end{itemize}
\end{textblock*}

\begin{textblock*}{8cm}(7.5cm,3.75cm)
\begin{center}
\includegraphics[width=2.3cm]{training.jpg}\\
\includegraphics[width=2.3cm]{test.jpg}
\end{center}
\end{textblock*}
\end{frame}





<<TestSet performance,echo=FALSE>>=

####OUT of sample testing##
#darch1<-readRDS("~/development/fogNNmodels/NNmodelTrainedWithStationCouplingEGU.RDS")

predictedRWSTest<-predict(darch1,dataMatTest, type = "bin")#predict(net,matRWSTest)
#
predictedRWSTest<-data.table(predictedRWSTest)
#
# #predictedRWS[,predictedLabels:=colnames(predictedRWS)[max.col(predictedRWS, ties.method = "first")]]
predictedRWSTest[,fog:=V2>0]
predictedRWSTest[,file:=filesTest]

confusionTest<-data.table(predicted=predictedRWSTest$fog,fogSensor=testing$foggy)

#table(confusionTest$predicted,confusionTest$fogSensor)

confMatrixTest<-confusionMatrix(confusionTest$predicted,confusionTest$fog, mode = "prec_recall", positive = "TRUE")


#draw_confusion_matrix_binary(confMatrixTest)
@




\begin{frame}{Pre-processing and network architecture}
\begin{textblock*}{8cm}(0.2cm,2.5cm)
\begin{center}
\begin{itemize}
\item Pre-processing of images:
\begin{itemize}
\item Scaling to 28x28 px to reduce feature space
\item Image blurring/smoothing to help against overfitting
\end{itemize}
\item Deep Neural Network: L$_{input}$: 2352, L$_1$:800, L$_2$:500, L$_3$:100, L$_{out}$:2
\end{itemize}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(6cm,2.5cm)
\begin{center}
\includegraphics[width=2cm]{private/original1.png}\\
\includegraphics[width=2cm]{private/resize1.png}\\
\includegraphics[width=2cm]{private/blurr1.png}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(0.7cm,5.75cm)
\begin{center}
\includegraphics[width=5cm]{DNN.png}
\end{center}
\end{textblock*}
\end{frame}













\begin{frame}{Results}
\begin{itemize}
\item Training set:
<<inSampleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
draw_confusion_matrix_binary(confMatrixTraining)
@
\end{itemize}
\end{frame}

\begin{frame}{Results (continued)}
\begin{itemize}
\item Test set:
 <<outOfSamepleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
  draw_confusion_matrix_binary(confMatrixTest)
@
 \end{itemize}
 \end{frame}


\begin{frame}{Conclusion and Outlook}
\begin{itemize}
\item Results looks promising, but better performance are needed for an operational service
\item Possibilities:
\begin{itemize}
\item Wait for the foggy period to get more images :-)
\item Manual labelling of the images far from meteo stations (labor intensive, any volunteers??)
\item Get more foggy images for training the network (partners welcome)
% \item Test a more advanced technique for image processing: convolutional neural networks
\end{itemize}
\item Next steps:
\begin{itemize}
\item Test with more classes of visibility (initial results)
\item Add meteo-related features
\item Fog at night time (?)
\end{itemize}
\end{itemize}
\end{frame}
%

% \begin{frame}{Conclusion}
% \begin{itemize}
% \item We are transitioning from a one-scene to \textbf{dynamic-scene} fog recognition
% \item Getting acquainted with new ML techniques (i.e., NN)
% \item Results look \textbf{good} from this last example
% \item \large Architecture for images and metadata handling essential to speed up and automate the analysis process. This aspect does \textbf{NOT} have to be underestimated for data science projects
% \item \normalsize Sometimes I miss Martin Roth! :-)
%
% \end{itemize}
% \end{frame}

\begin{frame}
\begin{textblock*}{8cm}(0.5cm,1.2cm)
\begin{center}
\includegraphics[width=9.3cm]{thanks.jpg}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(5.5cm,6.2cm)
\begin{center}
\includegraphics[width=4.3cm]{knmiDataLabLogoMail.png}
\end{center}
\end{textblock*}
\end{frame}
\end{document}

