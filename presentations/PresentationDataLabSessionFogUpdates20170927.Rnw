\documentclass[10pt,fleqn]{beamer}

\usepackage{lmodern}
\usepackage{knmiBeamer}
\usepackage{multirow}
\usepackage[skins]{tcolorbox}

\Engelstrue     % For English slides 
\renewcommand{\titleFigure}{../figure/fogCover.jpg}

\usepackage{tikz}
\usepackage{verbatim}
\usetikzlibrary{arrows, shapes}

% ---------------
% Graphics folder
% ---------------
\graphicspath{{../figure/}}

\title[Fog detection]{DataLab project: fog detection using cameras}
\subtitle{KNMI DataLab Meeting}
\date{September 27, 2017}
\author[Pagani, Roth, Wauben]{G.A. Pagani, M. Roth\\ and W. Wauben}
%\author[M. Roth (\MYhref{mailto:roth@knmi.nl}{roth@knmi.nl})]{Martin Roth\texorpdfstring{\\[2mm] \scriptsize \href{mailto:roth@knmi.nl}{roth@knmi.nl}\\[4mm] {\scriptsize Joint work with A. Buishand and G. Jongbloed}}{}}

\begin{document}
\tikzstyle{every picture}+=[remember picture]


<< Libraries, include=FALSE>>=
library(data.table)
library(imager)
library(visDec)
library(ggplot2)
library(rpart)
library(rattle)
library(rgdal)
library(ggmap)

library(DBI)
library(jsonlite)
library(data.table)
library(caret)
library(darch)


knitr::opts_chunk$set(echo = FALSE, cache = TRUE)

#setwd("~/development/fogDec/")

@

\begin{frame}
 \titlepage
\end{frame}

 \begin{frame}{Outline}
  \begin{itemize}
  \item Motivation for Fog
   \item Purpose
   \item Approach
   \item Results (till Dec 2016)
   \item RWS project phase (since Jan 2017)
   \item New results
   \item Conclusion
%   \item Idea and SWI
%   \item Dehaze algorithm
%   \item Results so far
%   \item Cameras and sensors
 \end{itemize}
 \end{frame}


% 20 MINUTES presentation




\begin{frame}{Fog as hazard}
 \begin{textblock*}{5cm}(7.4cm,2.4cm)
  \includegraphics[width=5cm]{Accident.jpeg}
 \end{textblock*}
 \begin{textblock*}{5cm}(7.4cm,5.5cm)
  \includegraphics[width=5cm]{airplane.jpg}
 \end{textblock*}
\begin{itemize}
  \item Substantial impact on air,\\ marine, and road traffic
  \item Loss of life comparable to that of\\ tornadoes or even winter storms\footnote{Gultepe, I. et al. (2007): Fog research: A review of past achievements and future perspectives. \emph{Pure and Applied Geophysics}, \textbf{164}, 1121--1159.}
  \item May form and dissipate suddenly
  \item Often only a local phenomenon
  \item Not easy to accurately forecast
  \item Satellites are not pointing to NL 24/7
 \end{itemize}
\end{frame}

\begin{frame}{Purpose, Scope, Benefits}
\begin{itemize}
\item \textbf{Purpose:} use cameras to identify fog conditions to issue safety hazards
\item \textbf{Scope:} daylight fog identification from static cameras using image analysis
\item \textbf{Benefits:}
\begin{itemize}
\item \textit{Society: }
\begin{itemize}
\item human lives
\item economic
\end{itemize}
\item \textit{KNMI:}
\begin{itemize}
\item better widespread observations of fog conditions
\item feed the fog observations in KNMI models (re-analysis) $\Rightarrow$ better fog modeling/predictions
\end{itemize}
\end{itemize}

\end{itemize}
\end{frame}

\begin{frame}{Approach: availability of sensors and traffic cameras}
 \begin{textblock*}{5cm}(1.2cm,3.0cm)
  \includegraphics[width=5cm]{SensorPlacement.png}
 \end{textblock*}
 \begin{textblock*}{5cm}(7.0cm,3.7cm)
  \includegraphics[width=5cm]{CameraPlacement.jpg}
 \end{textblock*}
\end{frame}



<< ExamplePictures, include=FALSE, cache=FALSE>>=
path <- system.file("../extdata/Meetterrein", package="visDec")
filenames <- list.files(path,
                        pattern=glob2rx("Meetterrein_201510*.jpg"),
                        full.names=TRUE)
@


\begin{frame}{Approach: Machine Learning in a small nutshell}
Machine learning is the systematic study of algorithms and systems that improve
their knowledge or performance with experience.
\begin{center}
\includegraphics[width=8cm]{figreML.png}
\end{center}

\end{frame}





\begin{frame}{Machine learning approach: features extracted from images}
\begin{itemize}
\begin{footnotesize}
\item{Mean Edges: for finding the boundaries of objects within images. It works by detecting discontinuities in the image (e.g., foreground and background elements).}
\item{Mean Brightness: perception of a source of radiating/reflecting light.}
\item{Mean Saturation: is a measure of the purity of the color. The purest (most saturated) color is achieved by using just one wavelength, less pure come from a combination at different wavelengths.}
\item{Mean HUE: perception of a source of being similar to one of the perceived colors: red, yellow, green, and blue, or to a combination of two of them.}
\item{Fractal Dimension: self similarity in filling space.}
\item{Transmission smoothness: transmission of the darkchannel of the image (smoothed indicator).}
\item{Transmission changepoint: horizontal point where the transmission of the dark channel is subject to change.}
\end{footnotesize}
\end{itemize}
\end{frame}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
\begin{frame}{Machine learning approach}
\vspace*{-5mm}
Example elaboration and feature: edge detection
<<LandmarkPlotClear, cache=TRUE, echo=FALSE, fig.height=4.2, fig.width=8.4>>=
im <- subim(load.image("../figure/Meetterrein_20150703_0320.jpg"), y > 16)


old_par <- par(mfrow=c(1,2))
plot(im)
#DetectEdges(im) %>% plot

#im <- subim(load.image(filenames[49]), y > 16)
#plot(im)
DetectEdges(im) %>% threshold(thr="98%") %>% plot()
par(old_par)
@
 \begin{textblock*}{10cm}(1.5cm,8cm)
  Consider the mean number of edges in the picture as feature.
 \end{textblock*}
\end{frame}





\begin{frame}{Machine Learning: De Bilt classification tree} 
\scriptsize{keys for reading a node:\\
 fraction of fog cases in the node/sub-tree\\
 \# of cases  \textemdash \% of total cases}
 
<<Classification, include=FALSE>>=
load("../results/deBiltResults2015.RData")
imageSummary[, dayIsEven := mday(dateOnly) %% 2]
train <- imageSummary[, .(dateTime, MOR, meanEdge, changePoint, meanBrightness)]
train <- na.omit(train)
train[, foggy := MOR < 250]
fogTree <- rpart(foggy ~ meanEdge + changePoint + meanBrightness, train , control = rpart.control(cp = 0.019))
pred <- predict(fogTree, train, method="class")
train[, pred := pred]
@
<<ClassificationTree, echo=FALSE, fig.height=4>>=
fancyRpartPlot(fogTree, sub="")
@
% keys for reading a node:
% fraction of fog cases in the node/sub-tree
% # of cases
% \% of total cases
\end{frame}


<<resultsDeBilt, include=FALSE, warning=FALSE>>=
dbConfig <- fromJSON("../config.json")



con <- dbConnect(RPostgreSQL::PostgreSQL(),
                 dbname = "FOGDB",
                 host = dbConfig[["host"]], port = 9418,
                 user = dbConfig[["user"]], password = dbConfig[["pw"]])



#Get meteo conditions for De Bilt
tableMeteo <- dbGetQuery(con, "SELECT * from meteo_features_stations
                                  WHERE location_id =1;")

#Get features for De Bilt images

tableFeatures <- dbGetQuery(con, "SELECT * from image_features
                                  WHERE camera_id =1;")


tableMeteo <- data.table(tableMeteo)
tableMeteo[, foggy := mor_visibility < 250]


tableFeatures <- data.table(tableFeatures)

setkey(tableFeatures,timestamp)

setkey(tableMeteo,timestamp)




fullTable <- tableFeatures[tableMeteo,]
train <- fullTable[year(timestamp)==2016,]
test <- fullTable[year(timestamp)<2016,]

train<-train[is.na(foggy)==FALSE]
train[,foggy:= as.factor(foggy)]
trainDB<-dim(train)[1]


test<-test[is.na(foggy)==FALSE]
test[,foggy:=as.factor(foggy)]
testDB<-dim(test)[1]



tree<-rpart(foggy~mean_edge+change_point+smoothness+fractal_dim+mean_hue+mean_saturation+mean_brightness, data=train)

#rf <- train(foggy~mean_edge+change_point+smoothness+fractal_dim+mean_hue+mean_saturation+mean_brightness, data=train, method="rf",na.action=na.exclude)

prova<-predict(tree, newdata = test, method ="class")
prova<-data.frame(prova)
matDB<-confusionMatrix(ifelse(prova$TRUE.>0.3, TRUE, FALSE), test$foggy,mode = "prec_recall", positive = "TRUE")

confMatDeBilt<-matDB$table
@


<<resultsCabauw, include=FALSE, warning=FALSE>>=
#Get meteo conditions for Cabauw

tableMeteo <- dbGetQuery(con, "SELECT * from meteo_features_stations
                                  WHERE location_id =3;")

#Get features for Cabauw images

tableFeatures <- dbGetQuery(con, "SELECT * from image_features
                                  WHERE camera_id =3;")


dbDisconnect(con)


tableMeteo <- data.table(tableMeteo)
tableMeteo[, foggy := mor_visibility < 250]


tableFeatures <- data.table(tableFeatures)

setkey(tableFeatures,timestamp)

setkey(tableMeteo,timestamp)




fullTable <- tableFeatures[tableMeteo,]
train <- fullTable[year(timestamp)==2017,]
test <- fullTable[year(timestamp)==2016,]

train<-train[is.na(foggy)==FALSE]
train[,foggy:= as.factor(foggy)]
trainCab<-dim(train)[1]


test<-test[is.na(foggy)==FALSE]
test[,foggy:=as.factor(foggy)]
testCab<-dim(test)[1]



tree<-rpart(foggy~mean_edge+change_point+smoothness+fractal_dim+mean_hue+mean_saturation+mean_brightness, data=train)

#rf <- train(foggy~mean_edge+change_point+smoothness+fractal_dim+mean_hue+mean_saturation+mean_brightness, data=train, method="rf",na.action=na.exclude)

prova<-predict(tree, newdata = test, method ="class")
prova<-data.frame(prova)
matCab<-confusionMatrix(ifelse(prova$TRUE.>0.3, TRUE, FALSE), test$foggy,mode = "prec_recall", positive = "TRUE")

confMatCabauw<-matCab$table

@

\begin{frame}{Results:}
\begin{textblock*}{4cm}(1.5cm,4.0cm)
De Bilt camera:\\ reference\\
\begin{textblock*}{4cm}(0cm,5cm) 
prediction
\end{textblock*}
\begin{footnotesize}
<<echo=FALSE>>=
kable(confMatDeBilt)
@
<<echo=FALSE>>=
kable(matDB$byClass[c(5,6,11)])
@
\end{footnotesize}
\vspace{0.2cm}
Train set (year 2016): \Sexpr{trainDB}\\
Test set (6-12/2015): \Sexpr{testDB}\\
\end{textblock*}

\begin{textblock*}{4cm}(8.0cm,4.0cm) 
Cabauw camera: reference\\
\begin{textblock*}{4cm}(6.5cm,5cm) 
prediction
\end{textblock*}
\begin{footnotesize}
<<echo=FALSE>>=
kable(confMatCabauw)
@
<<echo=FALSE>>=
kable(matCab$byClass[c(5,6,11)])
@
\end{footnotesize}
\vspace{0.2cm}
Train set (year 2017): \Sexpr{trainCab}\\
Test set (10-12/2016): \Sexpr{testCab}\\
\end{textblock*}

\end{frame}

\begin{frame}{Twente KNMI station}\centering
%The situation in Twente is different for two reasons, the wide angle of the
%camera makes the horizontal averaging of the transmission rate less appropriate.
%Moreover, even on a clear day there are only a few edges in the image (which are
%mostly very close to the camera, i.e. from the equipment of the automatic 
%weather station). Nevertheless, it was quite simple to detect failures of the 
%visibility sensor using the two described features, such as during the afternoon
%of August 23 2015, where the sensor consistently gave $MOR < 250$, although the 
%image is very clear.
 \includegraphics[width=5cm]{EHTW_201508231400.jpg}
 \begin{itemize}
  \item fish-eye lens
  \item only a few edges in the range of 50--250\,m
  \item fully unprotected camera
 \end{itemize}
\end{frame}




\begin{frame}{Twente: weather (un)protection}%\centering
\begin{columns}
\column{0.2\textwidth}
\includegraphics[height=2cm]{wideCamera}

\column{0.8\textwidth}
\includegraphics[height=3cm]{../inst/extdata/cornerCasesTwente/EHTW_201506280400.jpg} \\
\includegraphics[height=3cm]{../inst/extdata/cornerCasesTwente/EHTW_201510060700.jpg} \\

\end{columns}
\begin{textblock*}{5cm}(6.2cm,3.85cm)
Ice on the camera enclosure\\
\vspace{2.7cm}
Water drops on the camera enclosure
\end{textblock*}



\end{frame}








<<ClassificationTwente, echo=FALSE>>=
dataTwente <-readRDS("../results/ResultsTwente2015-2016_3hSun.rds")
 offsetBeforeSunrise <- 0
# #time in minutes
 offsetAfterSunset <- 0
 trainDeBilt <- imageSummary[dateTime> sunriseDateTime - offsetBeforeSunrise * 60 & dateTime < sunsetDateTime + offsetAfterSunset * 60, ]
dataTwente <- dataTwente[dateTime > sunriseDateTime & dateTime < sunsetDateTime, ]
 dataTwente[, foggy := MOR < 250]
 setkey(dataTwente, dateTime)
#
#
 source("../scripts/ReadMeteoData.R")
 windTwente <-ReadWindData("../inst/extdata/Sensor/TwenteWind1-1-2015-31-08-2016.csv")
 setkey(windTwente, dateTime)
#
#
humidityTwente <-ReadHumidityData("../inst/extdata/Sensor/TwenteHumidity1-1-2015-31-08-2016.csv")
 setkey(humidityTwente, dateTime)
#
#
 tempDewPointTwente <-ReadTempDewPointData("../inst/extdata/Sensor/TwenteTemp_DewPoint1-1-2015-31-08-2016.csv")
 setkey(tempDewPointTwente, dateTime)
#
#
precipitationTwente <-ReadPrecipitationData("../inst/extdata/Sensor/TwenteRainAll-1-2015-31-08-2016.csv")
 precipitationTwente[, rain := FALSE]
rainDuration <- 400
 precipitationTwente[precipitationDurationPWS > rainDuration | precipitationDurationElec > rainDuration, rain:= TRUE]
setkey(precipitationTwente, dateTime)
#
#
#
#
dataTwente <- SynchronizeSensorReadingsNoMORPicture(windTwente, dataTwente)
dataTwente <- SynchronizeSensorReadingsNoMORPicture(humidityTwente,dataTwente)
dataTwente <- SynchronizeSensorReadingsNoMORPicture(tempDewPointTwente, dataTwente)
dataTwente <- SynchronizeSensorReadingsNoMORPicture(precipitationTwente, dataTwente)
#
#
dataTwente <- na.omit(dataTwente)
#
trainTwente <- dataTwente[year==2015, .(dateTime, meanEdge, changePoint, smoothness, meanHue, meanSaturation, meanBrightness, MOR, foggy, day, month, hour, windSpeed, relHumidity, airTemperature, dewPoint, precipitationIntElec, precipitationIntPWS, precipitationDurationElec, precipitationDurationPWS, rain) ]
#
testTwente <- dataTwente[year==2016, .(dateTime, meanEdge, changePoint, smoothness, meanHue, meanSaturation, meanBrightness, MOR, foggy, day, month, hour, windSpeed, relHumidity, airTemperature, dewPoint, precipitationIntElec, precipitationIntPWS, precipitationDurationElec, precipitationDurationPWS, rain) ]
#
#
fogTree <- rpart(foggy ~ meanEdge + changePoint + meanBrightness, trainTwente, control = rpart.control(cp = 0.019))


twentePred<-predict(fogTree, newdata = testTwente, method ="class")
twentePred<-data.frame(twentePred)
matTwente<-confusionMatrix(ifelse(twentePred>0.3, TRUE, FALSE), testTwente$foggy,mode = "prec_recall", positive = "TRUE")


@



<<ClassificationTwenteMeteo, echo=FALSE>>=

 noRainDataTwente <- dataTwente[precipitationDurationElec<600 & windSpeed<3.5,]

 #noRainDataTwente <- noRainDataTwente[day!=23 & month!=08 & year!=2015,]

  removedFoggyRainOrHighWind <- dataTwente[foggy==TRUE, .N] - noRainDataTwente[foggy==TRUE, .N]
 datesOfFoggyRainOrHighWind <- dataTwente[dateTime%in%setdiff(dataTwente[foggy==TRUE]$dateTime,noRainDataTwente[foggy==TRUE]$dateTime)]$dateTime

trainTwenteNoRain <- noRainDataTwente[year==2015, .(dateTime, meanEdge, changePoint, smoothness, meanHue, meanSaturation, meanBrightness, MOR, foggy, day, month, hour, windSpeed, relHumidity, airTemperature, dewPoint, precipitationIntElec, precipitationIntPWS, precipitationDurationElec, precipitationDurationPWS, rain) ]

testTwenteNoRain <- noRainDataTwente[year==2016, .(dateTime, meanEdge, changePoint, smoothness, meanHue, meanSaturation, meanBrightness, MOR, foggy, day, month, hour, windSpeed, relHumidity, airTemperature, dewPoint, precipitationIntElec, precipitationIntPWS, precipitationDurationElec, precipitationDurationPWS, rain) ]

  fogTreeNoRain <- rpart(foggy ~ meanEdge + changePoint + meanBrightness +
                                   relHumidity + windSpeed + airTemperature + dewPoint + precipitationIntElec +
                                   precipitationIntPWS + precipitationDurationElec + precipitationDurationPWS,
                                   trainTwenteNoRain , control = rpart.control(cp = 0.015))

twentePredNoRain<-predict(fogTreeNoRain, newdata = testTwenteNoRain, method ="class")
twentePredNoRain<-data.frame(twentePredNoRain)
matTwenteNoRain<-confusionMatrix(ifelse(twentePredNoRain>0.3, TRUE, FALSE), testTwenteNoRain$foggy,mode = "prec_recall", positive = "TRUE")

@





\begin{frame}{Results Twente:}
\begin{textblock*}{4cm}(1.5cm,4.0cm)
Twente camera:\\ reference\\
\begin{textblock*}{4cm}(0cm,5cm)
prediction
\end{textblock*}
\begin{footnotesize}
<<echo=FALSE>>=
kable(matTwente$table)
@
<<echo=FALSE>>=
kable(matTwente$byClass[c(5,6,11)])
@
\end{footnotesize}
\vspace{0.2cm}
Train set (year 2015): \Sexpr{dim(trainTwente)[1]}\\
Test set (year 2016): \Sexpr{dim(testTwente)[1]}\\
\end{textblock*}

\begin{textblock*}{4cm}(8.0cm,4.0cm)
Twente camera rain+wind filtered\footnote{precipitationDurationElec$<$600 and windSpeed$<$3.5}: reference\\
\begin{textblock*}{4cm}(6.5cm,5cm)
prediction
\end{textblock*}
\begin{footnotesize}
<<echo=FALSE>>=
kable(matTwenteNoRain$table)
@
<<echo=FALSE>>=
kable(matTwenteNoRain$byClass[c(5,6,11)])
@
\end{footnotesize}
\vspace{0.2cm}
Train set (year 2015): \Sexpr{dim(trainTwenteNoRain)[1]}\\
Test set (year 2016): \Sexpr{dim(testTwenteNoRain)[1]}\\
\end{textblock*}

\end{frame}
% 
\begin{frame}{How to compute +100k images?}
\begin{textblock*}{5cm}(0.5cm,4cm)
\begin{itemize}
\item{Use of cloud providers}
\item{To avoid kill workstations}
\item{To learn this modern computation paradigm}
\item{Hands on with different providers}
\end{itemize}
 \end{textblock*}

\begin{textblock*}{5cm}(6cm,5cm)
  \includegraphics[width=5cm]{cloud.png}
 \end{textblock*}

\end{frame}


% 
\begin{frame}{Cloud investigation in a nutshell}
\vspace*{-0.25cm}
\begin{footnotesize}
\begin{center}
\hspace*{-0.5cm}
    \begin{tabular}{| p{1cm} | p{2cm} | p{3.5cm} | p{3.5cm} |}
    \hline
    Provider & Positive & Negative & Next steps \\ \hline
    Google & Up and running in minutes\newline Clear documentation & Limitations of free period (no clone, 1 machine) &
Test more machines and distributed setting\newline
Creation and administration via script \\ \hline
    Amazon & Clear-Easy documentation\newline Cloning\newline Shared storage & Free tier is very limited &
Test non-capped machines\newline Running more than 20 machines\newline Creation and administration via script\\ \hline
ECMWF & Free+- & Constraints of the architecture, languages, compilers\newline Limited experience in non traditional languages &
Wait for a solution of the bug \\ \hline
SurfSara & Kind technical service (once contacted)\newline Fast connectivity\newline &
Long time to up and running\newline
Open Nebula more confusing than “Big Providers”\newline
Less documentation\newline
Bugs/issues: time consuming &
Might be to exploit because KNMI is partner since recently\\ \hline

    \end{tabular}
\end{center}
\end{footnotesize}
\end{frame}

\begin{frame}{New project phase with RWS (since Jan 2017)}
\begin{itemize}
\item Goal: test approach in a more operational-oriented situation
\item Have more data (i.e., images) to test the approach
\item Deal with moving cameras
\item Re-size the approach to deal with more data feeds
\end{itemize}
\end{frame}
% 
\begin{frame}{More data sets}
\begin{columns}
\column{0.6\textwidth}
\begin{itemize}
\item More datasets have been hunted ;-)
\item Let's not talk about privacy issues, please!

\item New datasets:
\begin{itemize}
\item 4 Dutch airports: 7 cameras
\item 160 cameras along A15-A16-A4-A5-A1-A9-A50-A12-A27-A2 NL highways
\item 37 cameras along M90 Scottish motorway (test purposes)
\item 24 cameras Port of Rotterdam (advanced contacts)
\end{itemize}
\end{itemize}
\column{0.4\textwidth}
   \includegraphics[width=4.5cm]{schiphol.jpg}
   \vspace*{0.2cm}
  \includegraphics[width=4.5cm]{camerasRWS.png}
\end{columns}

\end{frame}




\begin{frame}{Scraping the web for GPS coordinates}
\begin{textblock*}{9cm}(0.2cm,2cm)
\begin{center}
\begin{itemize}
\item RWS has a different coordinate system: highway+hectimetre
\item We consider LAT-LON locations for cameras
\item GPS locations provided by RWS just 10 out of 160
\item Had to find a smart, fast, and easy way to get GPS coordinates of highways+hectometes
\item Web scraping becomes handy!
\item Website hmpaal.nl e.g., \tiny \url{http://www.hmpaal.nl/hectometer/A2/77.6/}
\normalsize
\item Python script that scrapes the GPS coordinates of highways+hectometes
\item Random cross-check with google streetview
\item For the highways+hectometes not available: \underline{time-consuming} search via google streetview (+-10/12 cases)
\end{itemize}
\end{center}
\end{textblock*}

\begin{textblock*}{6cm}(9cm,2.5cm)
\includegraphics[width=3.5cm]{webScraping.png}
\vspace{0.3cm}
\includegraphics[width=3.5cm]{hmPaal.PNG}
\end{textblock*}
\end{frame}




% 
\begin{frame}{From 1-camera analysis to a general solution}
\begin{itemize}
\item Thinking to a solution that can handle +100 cameras with:
\begin{itemize}
\item Centralized and persistent picture archiving
\item Archiving fault warning
\item Metadata extraction and storage at archival time
\item Ease of metadata and metrics access for faster analysis/modeling
\end{itemize}
\end{itemize}
\end{frame}
% 
\begin{frame}{Generic image archiving architecture implemented}

\includegraphics[width=10.75cm]{archiverArchitecture.png}

\end{frame}


\begin{frame}{DB design to archive metadata and image features computation}
Having the DB right is also important to streamline the analysis process down the road
\begin{center}
\includegraphics[width=8cm]{FogDBv6.png}
\end{center}
\end{frame}
% 
\begin{frame}{Flow for feature computation an ML model}
\begin{center}
\vspace*{-1cm}
\includegraphics[width=8cm]{computationFlow.png}
\end{center}


\begin{textblock*}{8cm}(6cm,7.5cm)
\begin{itemize}
   \item No more loose csv files with meteo
   \item No more loose rds files with feature computation
   \end{itemize}
 \end{textblock*}
\end{frame}

% 
\begin{frame}{New Results (old)}
\begin{itemize}
\item +2.2 million images archived
\item Initial investigation in domain adaptation fog dection:
\begin{itemize}
\item UVA master student investigated Neural Networks approach to analysis
\item Application of image domain adaptation technique with Neural Network led to accuracy (\underline{not balanced}) of 42.9\% for training set of Cabauw and test set of De Bilt (4 visibility classes)
\end{itemize}
\end{itemize}
\end{frame}
% 
% 
\begin{frame}{New Results (new)}
\begin{textblock*}{9.5cm}(0.1cm,2.2cm)
\begin{itemize}
\item New more general idea of fog detection.
\item Reason: scenary are too different also for the same camera (e.g., zoom)
\end{itemize}
\end{textblock*}
\begin{textblock*}{8cm}(7.5cm,2.2cm)
\begin{center}
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170801_0502.jpg}\\
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1232.jpg}\\
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1242.jpg}
\end{center}
\end{textblock*}
\begin{textblock*}{9.5cm}(0.1cm,3.5cm)
\begin{itemize}
\item Features is the whole picture: each pixel (of each of the RGB layers)
\item Use a deep neural network (InputL:2352,L1:800,L2:500,L3:100,L5:10,OutputL:2) to fit the model
\item Training set: +-750 random fog and +-750 non-fog pictures from De Bilt,Cabauw,Airports,A4 HM5-HM11 (i.e.,9 cameras)
\item Labels: from MOR sensor, fog considered if visibility $<=$250m
\begin{itemize}
\item NB: labels for A4 are taken from the Schiphol MOR sensor, manual check on a sub sample
\end{itemize}
\end{itemize}
\end{textblock*}
\end{frame}
% 
% 
<<NN highways, echo=FALSE>>=
#results for presentation


modelDarch<-readRDS("~/development/fogNNmodels/model1.rds")
dataMatTrain<-readRDS("~/development/fogNNmodels/trainingDataMat.RDS")
dataMatTest<-readRDS("~/development/fogNNmodels/testingDataMat.RDS")

testing<-readRDS("~/development/fogNNmodels/testingDataLabels.RDS")
training<-readRDS("~/development/fogNNmodels/trainingDataLabels.RDS")

filesTest<-readRDS("~/development/fogNNmodels/filenamesTest.RDS")
files<-readRDS("~/development/fogNNmodels/trainingFileNames.RDS")


dtMat<-data.table(dataMatTrain)
#dtMat[,vis_class:=res2$vis_class]
dtMat[,foggy:=training$foggy]


###In sample testing#####
predictedRWS<-predict(modelDarch,dataMatTrain, type = "bin")
#predict(net,matRWS)
#
predictedRWS<-data.table(predictedRWS)
#
# #predictedRWS[,predictedLabels:=colnames(predictedRWS)[max.col(predictedRWS, ties.method = "first")]]
predictedRWS[,fog:=V2>0]
predictedRWS[,file:=files]



confusion<-data.table(predicted=predictedRWS$fog,fogSensor=dtMat$foggy)

#table(confusion$predicted,confusion$fogSensor)

confInSample<-confusionMatrix(confusion$predicted,confusion$fog, mode = "prec_recall", positive = "TRUE")




####OUT of sample testing##
predictedRWSTest<-predict(modelDarch,dataMatTest, type = "bin")#predict(net,matRWSTest)
#
predictedRWSTest<-data.table(predictedRWSTest)
#
# #predictedRWS[,predictedLabels:=colnames(predictedRWS)[max.col(predictedRWS, ties.method = "first")]]
predictedRWSTest[,fog:=V2>0]
predictedRWSTest[,file:=filesTest]



confusionTest<-data.table(predicted=predictedRWSTest$fog,fogSensor=testing$foggy)

#table(confusionTest$predicted,confusionTest$fogSensor)

confOutSample<-confusionMatrix(confusionTest$predicted,confusionTest$fog, mode = "prec_recall", positive = "TRUE")


@

% 

<<confusionDraw, echo=FALSE>>=

draw_confusion_matrix <- function(cm) {

  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, 'FALSE', cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, 'TRUE', cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, 'FALSE', cex=1.2, srt=90)
  text(140, 335, 'TRUE', cex=1.2, srt=90)

  # add in the cm results
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information
  text(50, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(50, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  #text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  #text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}
@



\begin{frame}{New Results (new continued)}
\begin{itemize}
\item Test set: 4000 random non-fog images, 334 foggy images (not part of training set, obviously)

\item Results:
\begin{itemize}
\item In-sample:
<<inSampleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
draw_confusion_matrix(confInSample)
@
\end{itemize}
\end{itemize}
\end{frame}

 \begin{frame}{New Results (new continued)}
 \begin{itemize}
\item Results:
 \begin{itemize}
 \item Out-of-sample:
 <<outOfSamepleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
 draw_confusion_matrix(confOutSample)
 @

 \end{itemize}
 \end{itemize}

 \end{frame}

% 
\begin{frame}{Next steps: many!}
\begin{itemize}
\item Wait for the foggy period to get more images :-)
\item Test the approach on other highways and manually examine the labels (labor intensive, any volunteers??)
\item Get more for images for training the network from UK MetOffice (contacts at EGU2017)
\item Test a more advanced techniques: convolutional neural networks
\item test with more classes of visibility
\end{itemize}
\end{frame}


\begin{frame}{Conclusion}
\begin{itemize}
\item We are transitioning from a one-scene to dynamic-scene fog recognition
\item Getting acquainted with new ML techniques (i.e., NN)
\item Results look good from this last example
\item \large Architecture for images and metadata handling essential to speed up and automate the analysis process. This aspect does \textbf{NOT} have to be underestimated for data science projects.
\item \normalsize Sometimes I miss Martin Roth! :-)

\end{itemize}
\end{frame}


\end{document}