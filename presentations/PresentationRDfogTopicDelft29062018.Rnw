\documentclass[10pt,fleqn]{beamer}
 
\usepackage{lmodern}
\usepackage{knmiBeamer}
\usepackage{multirow}
\usepackage[skins]{tcolorbox}

\Engelstrue     % For English slides 
\renewcommand{\titleFigure}{../figure/fogCover.jpg}

\usepackage{tikz}
\usepackage{verbatim}
\usetikzlibrary{arrows, shapes}

% ---------------
% Graphics folder
% ---------------
\graphicspath{{../figure/}}


\title[Automatic fog detection]{Automatic fog detection using surveillance camera images}
%\Subtitletrue
%\subtitle{abc}
\date{June 29, 2018}
\author[Pagani, Noteboom, Wauben and Eyk]{\scriptsize{Pagani, Noteboom, Wauben (KNMI) \\and Eyk (RWS)}}

\begin{document}
\tikzstyle{every picture}+=[remember picture]


\begin{frame}
 \titlepage
 \begin{textblock*}{5cm}(7cm,8.4cm)
 \begin{tiny}
 \textit{R\&D meeting: fog forecacast \\Delft, June 29, 2018}
 \end{tiny}
 \end{textblock*}
\end{frame}


% \begin{frame}{Outline}
% \begin{itemize}
%   \item Motivation for Fog research
%    \item Purpose
%    \item Sensors vs. cameras
%    \item Data sets
%    \item Neural Networks
%    \item Results
%    \item Next steps
% \end{itemize}
% \end{frame}



<<Libraries, include=FALSE>>=
library(data.table)
library(imager)
library(visDec)
library(ggplot2)
library(rpart)
library(rattle)
library(rgdal)
library(ggmap)

library(DBI)
library(jsonlite)
library(data.table)
library(caret)
library(darch)
library(latex2exp)


knitr::opts_chunk$set(echo = FALSE, cache = TRUE)
knitr::opts_chunk$set(error = TRUE)

#setwd("~/development/fogDec/")

@


\begin{frame}{Fog as hazard}
 \begin{textblock*}{5cm}(7.4cm,2.4cm)
  \includegraphics[width=5cm]{Accident.jpeg}
 \end{textblock*}
 \begin{textblock*}{5cm}(7.4cm,5.5cm)
  \includegraphics[width=5cm]{airplane.jpg}
 \end{textblock*}

\begin{textblock*}{7cm}(0.2cm,4.25cm)
\begin{itemize}
  \item Substantial impact on air, marine, and road traffic
  %\item Loss of life comparable to that of tornadoes or even winter storms\footnote{Gultepe, I. et al. (2007): Fog research: A review of past achievements and future perspectives. \emph{Pure and Applied Geophysics}, \textbf{164}, 1121--1159.}
  \item Forms and dissipates suddenly
  %\item Often  local phenomenon
  \item Not easy to accurately forecast
 \end{itemize}
  \end{textblock*}
\end{frame}



\begin{frame}{Purpose, Scope, Benefits of the project}
\begin{itemize}
\item \textbf{Purpose:} use cameras to identify fog conditions to issue safety hazards
\item \textbf{Scope:} daylight fog identification from static scenery cameras using image analysis
\item \textbf{Benefits:}
\begin{itemize}
\item \textit{Society: }
\begin{itemize}
\item human lives
\item economic
\end{itemize}
\item \textit{KNMI:}
\begin{itemize}
\item better widespread observations of fog conditions
\item feed the fog observations in KNMI models (re-analysis) $\Rightarrow$ better fog modeling/predictions
\end{itemize}
\end{itemize}
\end{itemize}
\end{frame}






\begin{frame}{Traditional sensors vs. traffic cameras}
%\begin{itemize}
% \item Satellites are not pointing to NL 24/7
%   \item But maybe other ubiquitous ``sensors'' can be used e.g., traffic cameras
%   \end{itemize}
   \begin{textblock*}{5cm}(0.5cm,4.0cm)
  \includegraphics[width=4cm]{fogSat.jpg}
 \end{textblock*}
 \begin{textblock*}{5cm}(4.95cm,4.0cm)
  \includegraphics[width=3cm]{SensorPlacement.png}
 \end{textblock*}
 \begin{textblock*}{5cm}(8.4cm,4cm)
  \includegraphics[width=4cm]{CameraPlacement.jpg}
 \end{textblock*}
\end{frame}

\begin{frame}{Approach: Big Data and Machine Learning}
\begin{textblock*}{12cm}(0.2cm,2.2cm)
\begin{itemize}
\begin{small}
\item Use big amount of data (i.e., images) to train models that can discriminate different (i.e., fog/non-fog) conditions.

\item Machine learning is the systematic study of algorithms and systems that improve
their knowledge or performance with experience.
\end{small}
\end{itemize}
\end{textblock*}
\begin{textblock*}{12cm}(0.2cm,3.75cm)
\begin{center}
\includegraphics[width=7cm]{figreML.png}
\end{center}
\end{textblock*}
\end{frame}

\begin{frame}{Data sets available}
\begin{columns}
\column{0.6\textwidth}
\begin{itemize}
\item 6 KNMI stations: 10 cameras (since 04/2016)
\item 160 cameras along Dutch highways (since 07/2018)
\item image sampling every 10 minutes
\item $\pm$ 9 million images archived
\item $\pm$ 2 million labeled
\end{itemize}
\column{0.4\textwidth}
   \includegraphics[width=4.5cm]{schiphol.jpg}
   \vspace*{0.2cm}
  \includegraphics[width=4.5cm]{camerasRWS.png}
\end{columns}

\end{frame}



\begin{frame}{Approach: Neural Network (in a nutshell)}
\begin{textblock*}{8cm}(0.5cm,3cm)
\begin{itemize}
\item Inspired by the functioning and firing of neurons in the brain
\item Allows the fitting of complex non-linear classification tasks
\item Works good with many input e.g., high order interaction terms
%would explode (e.g., 25x25px gray-scale image and we want quadratic interaction terms requires 3 millions features)
\item Training the network and tune the performance takes long time
\item Activation function can be customized (usually sigmoid-like function)
\end{itemize}
\end{textblock*}
\begin{textblock*}{8cm}(6.5cm,3cm)
\begin{center}
\includegraphics[width=3cm]{nnet.png}\\
\includegraphics[width=3cm]{artificial.jpg}
\end{center}
\end{textblock*}
\end{frame}


\begin{frame}{Why Neural Networks?}
\begin{textblock*}{9.5cm}(0.5cm,3.2cm)
\begin{itemize}
\item Used proficiently in image processing and image classification
\item More general method of fog detection than our previous attempt with decision trees and image features
\item Sceneries are too different also for the same camera (e.g., zoom)
\item Features are each pixel (of each of the RGB layers)
%\item Use a deep neural network (InputL:2352,L1:800,L2:500,L3:100,L5:10,OutputL:2) to fit the model
\end{itemize}
\end{textblock*}
\begin{textblock*}{8cm}(7.5cm,2.2cm)
\begin{center}
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170801_0502.jpg}\\
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1232.jpg}\\
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1242.jpg}
\end{center}
\end{textblock*}
\end{frame}





<<confusionDraw, echo=FALSE, include=FALSE>>=
draw_confusion_matrix_binary <- function(cm) {

     layout(matrix(c(1,1,2)))
     par(mar=c(2,2,2,2))
     plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
     title('CONFUSION MATRIX', cex.main=2)

     # create the matrix
     rect(150, 430, 240, 370, col='#3F97D0')
     text(195, 435, 'FALSE', cex=1.2)
     rect(250, 430, 340, 370, col='#F7AD50')
     text(295, 435, 'TRUE', cex=1.2)
     text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
     text(245, 450, 'Actual', cex=1.3, font=2)
     rect(150, 305, 240, 365, col='#F7AD50')
     rect(250, 305, 340, 365, col='#3F97D0')
     text(140, 400, 'FALSE', cex=1.2, srt=90)
     text(140, 335, 'TRUE', cex=1.2, srt=90)

     # add in the cm results
     res <- as.numeric(cm$table)
     text(195, 400, res[1], cex=1.6, font=2, col='white')
     text(195, 335, res[2], cex=1.6, font=2, col='white')
     text(295, 400, res[3], cex=1.6, font=2, col='white')
     text(295, 335, res[4], cex=1.6, font=2, col='white')

     # add in the specifics
     plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
     #text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
     #text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
     #text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
     #text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
     text(10, 85, names(cm$byClass[5]), cex=1.4, font=2)
     text(10, 65, round(as.numeric(cm$byClass[5]), 3), cex=1.4)
     text(30, 85, names(cm$byClass[6]), cex=1.4, font=2)
     text(30, 65, round(as.numeric(cm$byClass[6]), 3), cex=1.4)
     text(50, 85, names(cm$byClass[7]), cex=1.4, font=2)
     text(50, 65, round(as.numeric(cm$byClass[7]), 3), cex=1.4)

     # add in the accuracy information
     text(80, 85, names(cm$overall[1]), cex=1.4, font=2)
     text(80, 65, round(as.numeric(cm$overall[1]), 3), cex=1.4)
     #text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
     #text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
   }
@

<<NN highways, echo=FALSE, include=FALSE>>=
#results for presentation

darch1<-readRDS("~/development/fogNNmodels/NNmodelTrainedWithStationCouplingEGU.RDS")
dataMatTrain<-readRDS("~/development/fogNNmodels/trainingDataMatEGU.RDS")
dataMatTest<-readRDS("~/development/fogNNmodels/testingDataMatEGU.RDS")

testing<-readRDS("~/development/fogNNmodels/testingDataLabelsEGU.RDS")
training<-readRDS("~/development/fogNNmodels/trainingDataLabelsEGU.RDS")

filesTest<-readRDS("~/development/fogNNmodels/filenamesTestEGU.RDS")
files<-readRDS("~/development/fogNNmodels/trainingFileNamesEGU.RDS")

predictedRWS<-predict(darch1,dataMatTrain, type = "bin")
predictedRWS<-data.table(predictedRWS)
predictedRWS[,fog:=V2>0]
predictedRWS[,file:=files]

confusion<-data.table(predicted=predictedRWS$fog,fogSensor=training$foggy)

#table(confusion$predicted,confusion$fog)

confMatrixTraining<-confusionMatrix(confusion$predicted,confusion$fog, mode = "prec_recall", positive = "TRUE")
@


\begin{frame}{Training and Test sets}
\begin{textblock*}{9.5cm}(0.5cm,3.5cm)
\begin{itemize}
\item Labels: from forward scatter visibility sensor that provides mteorological optical range (MOR)
\item Fog considered if visibility is $\leq$ 250m
\item Point of concern: labels for highway cameras are given by a KNMI station in a radius of 7.5km
\item Balanced training set: $\pm$ \Sexpr{round(sum(training$foggy/100))*100} random fog and $\pm$ \Sexpr{round(sum(training$foggy==FALSE)/100)*100} non-fog images from \Sexpr{length(unique(training$camera_id))} cameras
\item Test set: $\pm$ \Sexpr{round(sum(testing$foggy)/100)*100} fog and  $\pm$ \Sexpr{round(sum(testing$foggy==FALSE)/100)*100} non-fog images
\end{itemize}
\end{textblock*}

\begin{textblock*}{8cm}(7.5cm,3.75cm)
\begin{center}
\includegraphics[width=2.3cm]{training.jpg}\\
\includegraphics[width=2.3cm]{test.jpg}
\end{center}
\end{textblock*}
\end{frame}





<<TestSet performance,echo=FALSE>>=

####OUT of sample testing##
#darch1<-readRDS("~/development/fogNNmodels/NNmodelTrainedWithStationCouplingEGU.RDS")

predictedRWSTest<-predict(darch1,dataMatTest, type = "bin")#predict(net,matRWSTest)
#
predictedRWSTest<-data.table(predictedRWSTest)
#
# #predictedRWS[,predictedLabels:=colnames(predictedRWS)[max.col(predictedRWS, ties.method = "first")]]
predictedRWSTest[,fog:=V2>0]
predictedRWSTest[,file:=filesTest]

confusionTest<-data.table(predicted=predictedRWSTest$fog,fogSensor=testing$foggy)

#table(confusionTest$predicted,confusionTest$fogSensor)

confMatrixTest<-confusionMatrix(confusionTest$predicted,confusionTest$fog, mode = "prec_recall", positive = "TRUE")


#draw_confusion_matrix_binary(confMatrixTest)
@




\begin{frame}{Pre-processing and network architecture}
\begin{textblock*}{8cm}(0.2cm,2.5cm)
\begin{center}
\begin{itemize}
\item Pre-processing of images:
\begin{itemize}
\item Scaling to 28x28 px to reduce feature space
\item Image blurring/smoothing to help against overfitting
\end{itemize}
\item Deep Neural Network: L$_{input}$: 2352, L$_1$:800, L$_2$:500, L$_3$:100, L$_{out}$:2
\end{itemize}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(6cm,2.5cm)
\begin{center}
\includegraphics[width=2cm]{private/original1.png}\\
\includegraphics[width=2cm]{private/resize1.png}\\
\includegraphics[width=2cm]{private/blurr1.png}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(0.7cm,5.75cm)
\begin{center}
\includegraphics[width=5cm]{DNN.png}
\end{center}
\end{textblock*}
\end{frame}





<<confusionDrawExplanation, echo=FALSE, include=FALSE>>=
draw_confusion_matrix_binary_explanation <- function() {

     layout(matrix(c(1,1,2)))
     par(mar=c(2,2,2,2))
     plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
     title('CONFUSION MATRIX', cex.main=2)

     # create the matrix
     rect(150, 430, 240, 370, col='#3F97D0')
     text(195, 435, 'FALSE', cex=1.2)
     rect(250, 430, 340, 370, col='#F7AD50')
     text(295, 435, 'TRUE', cex=1.2)
     text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
     text(245, 450, 'Actual', cex=1.3, font=2)
     rect(150, 305, 240, 365, col='#F7AD50')
     rect(250, 305, 340, 365, col='#3F97D0')
     text(140, 400, 'FALSE', cex=1.2, srt=90)
     text(140, 335, 'TRUE', cex=1.2, srt=90)

     # add in the cm results
     #res <- as.numeric(cm$table)
     text(195, 400, "TN", cex=1.6, font=2, col='white')
     text(195, 335, "FP", cex=1.6, font=2, col='white')
     text(295, 400, "FN", cex=1.6, font=2, col='white')
     text(295, 335, "TP", cex=1.6, font=2, col='white')

     # add in the specifics
     plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
     text(10, 85, "Precision", cex=1.4, font=2)
     text(10, 50, TeX("\\frac{TP}{TP+FP}$"), cex=1.4)
     text(30, 85, "Recall", cex=1.4, font=2)
     text(30, 50, TeX("\\frac{TP}{TP+FN}$"), cex=1.4)
     text(55, 85, "F1 Score", cex=1.4, font=2)
     text(55, 50, TeX("\\frac{$2\\cdot$Precision$\\cdot$Recall}{Precision+Recall}"), cex=1.4)


     # add in the accuracy information
     text(80, 85, "Accuracy", cex=1.4, font=2)
     text(80, 50, TeX("\\frac{TP+TN}{TP+TN+FP+FN}$"), cex=1.4)
     #text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
     #text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
   }
@



\begin{frame}{Evaluation of performance}
\begin{textblock*}{5.3cm}(0.2cm,2.75cm)
\begin{itemize}
\item Accuracy can be misleading especially in unbalanced datasets like this one.
\item Better to use:
\begin{itemize}
\item Precision: fraction of items selected that are relevant (correct) ($Prec=\frac{TP}{TP+FP}$)
\item Recall: fraction of items correctly selected on all the relevant items  ($Rec=\frac{TP}{TP+FN}$)
\item F1 Score: harmonic mean of precision and recall
\end{itemize}
\end{itemize}
\end{textblock*}
\begin{textblock*}{7cm}(5.5cm,3.75cm)
 <<confusionExplanation, echo=FALSE, fig.height=5, fig.width=8>>=
draw_confusion_matrix_binary_explanation()
@
\end{textblock*}
\end{frame}





\begin{frame}{Results}
\begin{itemize}
\item Training set:
<<inSampleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
draw_confusion_matrix_binary(confMatrixTraining)
@
\end{itemize}
\end{frame}

\begin{frame}{Results (continued)}
\begin{itemize}
\item Test set:
 <<outOfSamepleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
  draw_confusion_matrix_binary(confMatrixTest)
@
 \end{itemize}
 \end{frame}


\begin{frame}{Current situation and Outlook}
\begin{itemize}
\item Results looks promising, but better performance are needed for an operational service
\item Possibilities:
\begin{itemize}
\item Wait for the foggy period to get more images :-)
\item Manual labelling of the images far from meteo stations (labor intensive, any volunteers??)
\item Get more foggy images for training the network (partners welcome)
% \item Test a more advanced technique for image processing: convolutional neural networks
\end{itemize}

\item Current steps:
\begin{itemize}
\item Real time fog detection for POC application for Weather/Traffic-Room
\item More cameras of ``spitsstook'' available for POC
\item UvA data science student master thesis at KNMI
\end{itemize}

\item Next steps:
\begin{itemize}
\item Test with more classes of visibility (initial results)
\item Add meteo-related features
\item Fog at night time (?)
\item Collaboration with J{\"u}lich Supercomputing Center on CNN model
\end{itemize}
\end{itemize}
\end{frame}
%

% \begin{frame}{Conclusion}
% \begin{itemize}
% \item We are transitioning from a one-scene to \textbf{dynamic-scene} fog recognition
% \item Getting acquainted with new ML techniques (i.e., NN)
% \item Results look \textbf{good} from this last example
% \item \large Architecture for images and metadata handling essential to speed up and automate the analysis process. This aspect does \textbf{NOT} have to be underestimated for data science projects
% \item \normalsize Sometimes I miss Martin Roth! :-)
%
% \end{itemize}
% \end{frame}

\begin{frame}
\begin{textblock*}{8cm}(0.5cm,1.2cm)
\begin{center}
\includegraphics[width=9.3cm]{thanks.jpg}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(5.5cm,6.2cm)
\begin{center}
\includegraphics[width=4.3cm]{knmiDataLabLogoMail.png}
\end{center}
\end{textblock*}
\end{frame}
\end{document}

