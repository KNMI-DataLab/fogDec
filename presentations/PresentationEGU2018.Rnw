\documentclass[10pt,fleqn]{beamer}

\usepackage{lmodern}
\usepackage{knmiBeamer}
\usepackage{multirow}
\usepackage[skins]{tcolorbox}

\Engelstrue     % For English slides 
\renewcommand{\titleFigure}{../figure/fogCover.jpg}

\usepackage{tikz}
\usepackage{verbatim}
\usetikzlibrary{arrows, shapes}

% ---------------
% Graphics folder
% ---------------
\graphicspath{{../figure/}}

\title[NN for automatic fog detection]{Neural network approach for automatic fog detection using surveillance
camera images}
%\subtitle{KNMI DataLab Meeting}
\date{April 9, 2018}
\author[Pagani, Noteboom, Wauben]{Pagani, Noteboom and Wauben}

\begin{document}
\tikzstyle{every picture}+=[remember picture]


\begin{frame}
 \titlepage
 \begin{textblock*}{5cm}(7cm,8.4cm)
 \begin{tiny}
 \textit{
 EGU 2018 - Big data and machine learning in geosciences session\\
 April 9, 2018
 }
 \end{tiny}
 \end{textblock*}
\end{frame}



% \begin{frame}{Outline}
% \begin{itemize}
%   \item Motivation for Fog research
%    \item Purpose
%    \item Sensors vs. cameras
%    \item Data sets
%    \item Neural Networks
%    \item Results
%    \item Next steps
% \end{itemize}
% \end{frame}


<< Libraries, include=FALSE>>=
library(data.table)
library(imager)
library(visDec)
library(ggplot2)
library(rpart)
library(rattle)
library(rgdal)
library(ggmap)

library(DBI)
library(jsonlite)
library(data.table)
library(caret)
library(darch)


knitr::opts_chunk$set(echo = FALSE, cache = TRUE)

#setwd("~/development/fogDec/")

@




\begin{frame}{Fog as hazard}
 \begin{textblock*}{5cm}(7.4cm,2.4cm)
  \includegraphics[width=5cm]{Accident.jpeg}
 \end{textblock*}
 \begin{textblock*}{5cm}(7.4cm,5.5cm)
  \includegraphics[width=5cm]{airplane.jpg}
 \end{textblock*}

\begin{textblock*}{7cm}(0.2cm,3cm)
\begin{itemize}
  \item Substantial impact on air, marine, and road traffic
  %\item Loss of life comparable to that of tornadoes or even winter storms\footnote{Gultepe, I. et al. (2007): Fog research: A review of past achievements and future perspectives. \emph{Pure and Applied Geophysics}, \textbf{164}, 1121--1159.}
  \item Form and dissipate suddenly
  %\item Often  local phenomenon
  \item Not easy to accurately forecast
  
 \end{itemize}
  \end{textblock*}
\end{frame}


\begin{frame}{Goal & Scope}
\begin{itemize}
\item \textbf{Purpose:} use cameras to identify fog conditions to issue safety warnings
\item \textbf{Value:}
\begin{itemize}
\item \textit{Society: }
\begin{itemize}
\item human lives
\item economic
\end{itemize}
\item \textit{KNMI:}
\begin{itemize}
\item more fog observations
\item improve modeling/fog predictions
\end{itemize}

\end{itemize}
\item \textbf{Scope:} daylight fog identification from static and moving cameras using image analysis

\end{itemize}
\end{frame}

\begin{frame}{Traditional sensors vs. traffic cameras}
\begin{itemize}
% \item Satellites are not pointing to NL 24/7
%   \item But maybe other ubiquitous ``sensors'' can be used e.g., traffic cameras
%   \end{itemize}
   \begin{textblock*}{5cm}(0.2cm,3.0cm)
  \includegraphics[width=3cm]{fogSat.jpg}
 \end{textblock*}
 \begin{textblock*}{5cm}(1.2cm,3.0cm)
  \includegraphics[width=3cm]{SensorPlacement.png}
 \end{textblock*}
 \begin{textblock*}{5cm}(7.0cm,3.7cm)
  \includegraphics[width=3cm]{CameraPlacement.jpg}
 \end{textblock*}
\end{frame}

\begin{frame}{Data sets available}
\begin{columns}
\column{0.6\textwidth}
\begin{itemize}
\item 6 KNMI stations: 10 cameras (since 04/2016)
\item 160 cameras along Dutch highways (since 07/2018)
\item image sampling every 10 minutes
\item \pm 7 million images archived
\item \pm 1.5 million labeled
\end{itemize}
\column{0.4\textwidth}
   \includegraphics[width=4.5cm]{schiphol.jpg}
   \vspace*{0.2cm}
  \includegraphics[width=4.5cm]{camerasRWS.png}
\end{columns}

\end{frame}



\begin{frame}{Approach: Neural Network (in a nutshell)}
\begin{textblock*}{8cm}(0.5cm,2.2cm)
\begin{itemize}
\item Inspired by the functioning and firing of neurons in the brain
\item Allows the fitting of complex non-linear classification tasks
\item Works good with many input e.g., high order interaction terms
%would explode (e.g., 25x25px gray-scale image and we want quadratic interaction terms requires 3 millions features)
\item Training the network and tune the performance takes long time
\item Activation function can be customized (usually sigmoid-like function)
\end{itemize}
\end{textblock*}
\begin{textblock*}{8cm}(6.5cm,3cm)
\begin{center}
\includegraphics[width=3cm]{nnet.png}\\
\includegraphics[width=3cm]{artificial.jpg}
\end{center}
\end{textblock*}
\end{frame}


\begin{frame}{Why Neural Networks?}
\begin{textblock*}{9.5cm}(0.5cm,3.2cm)
\begin{itemize}
\item Used proficiently in image processing and image classification
\item More general method of fog detection than our previous attempt with decision trees and image features
\item Sceneries are too different also for the same camera (e.g., zoom)
\item Features are each pixel (of each of the RGB layers)
%\item Use a deep neural network (InputL:2352,L1:800,L2:500,L3:100,L5:10,OutputL:2) to fit the model
\end{itemize}
\end{textblock*}
\begin{textblock*}{8cm}(7.5cm,2.2cm)
\begin{center}
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170801_0502.jpg}\\
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1232.jpg}\\
\includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1242.jpg}
\end{center}
\end{textblock*}
\end{frame}



<<confusionDraw, echo=FALSE>>=
draw_confusion_matrix_binary <- function(cm) {

     layout(matrix(c(1,1,2)))
     par(mar=c(2,2,2,2))
     plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
     title('CONFUSION MATRIX', cex.main=2)

     # create the matrix
     rect(150, 430, 240, 370, col='#3F97D0')
     text(195, 435, 'FALSE', cex=1.2)
     rect(250, 430, 340, 370, col='#F7AD50')
     text(295, 435, 'TRUE', cex=1.2)
     text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
     text(245, 450, 'Actual', cex=1.3, font=2)
     rect(150, 305, 240, 365, col='#F7AD50')
     rect(250, 305, 340, 365, col='#3F97D0')
     text(140, 400, 'FALSE', cex=1.2, srt=90)
     text(140, 335, 'TRUE', cex=1.2, srt=90)

     # add in the cm results
     res <- as.numeric(cm$table)
     text(195, 400, res[1], cex=1.6, font=2, col='white')
     text(195, 335, res[2], cex=1.6, font=2, col='white')
     text(295, 400, res[3], cex=1.6, font=2, col='white')
     text(295, 335, res[4], cex=1.6, font=2, col='white')

     # add in the specifics
     plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
     text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
     text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
     text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
     text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
     text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
     text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
     text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
     text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
     text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
     text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

     # add in the accuracy information
     text(50, 35, names(cm$overall[1]), cex=1.5, font=2)
     text(50, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
     #text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
     #text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
   }
 @



<<NN highways, echo=FALSE>>=
#results for presentation

darch1<-readRDS("~/development/fogNNmodels/NNmodelTrainedWithStationCouplingEGU.RDS")
dataMatTrain<-readRDS("~/development/fogNNmodels/trainingDataMatEGU.RDS")
dataMatTest<-readRDS("~/development/fogNNmodels/testingDataMatEGU.RDS")

testing<-readRDS("~/development/fogNNmodels/testingDataLabelsEGU.RDS")
training<-readRDS("~/development/fogNNmodels/trainingDataLabelsEGU.RDS")

filesTest<-readRDS("~/development/fogNNmodels/filenamesTestEGU.RDS")
files<-readRDS("~/development/fogNNmodels/trainingFileNamesEGU.RDS")

predictedRWS<-predict(darch1,dataMatTrain, type = "bin")
predictedRWS<-data.table(predictedRWS)
predictedRWS[,fog:=V2>0]
predictedRWS[,file:=files]

confusion<-data.table(predicted=predictedRWS$fog,fogSensor=training$foggy)

#table(confusion$predicted,confusion$fog)

confMatrixTraining<-confusionMatrix(confusion$predicted,confusion$fog, mode = "prec_recall", positive = "TRUE")
@

\begin{frame}{Training and Test sets}
\begin{textblock*}{9.5cm}(0.5cm,3.5cm)
\begin{itemize}
\item Labels: from forward scatter visibility sensor that provides mteorological optical range (MOR)
\item Fog considered if visibility is $\leq$250m
\item Point of concern: labels for highway cameras are given by a KNMI station in a radius of 7.5km
\item Balanced training set: \pm \Sexpr{round(sum(training$foggy/100))*100} random fog and \pm \Sexpr{round(sum(training$foggy==FALSE)/100)*100} non-fog images from \Sexpr{length(unique(training$camera_id))} cameras
\item Test set: +-\Sexpr{round(sum(testing$foggy)/100)*100} fog and  +-\Sexpr{round(sum(testing$foggy==FALSE)/100)*100} non-fog images

\end{itemize}
\end{textblock*}

\begin{textblock*}{8cm}(7.5cm,3.75cm)
\begin{center}
\includegraphics[width=2.3cm]{training.jpg}\\
\includegraphics[width=2.3cm]{test.jpg}
\end{center}
\end{textblock*}
\end{frame}

<<TestSet performance,echo=FALSE>>=

####OUT of sample testing##
#darch1<-readRDS("~/development/fogNNmodels/NNmodelTrainedWithStationCouplingEGU.RDS")

predictedRWSTest<-predict(darch1,dataMatTest, type = "bin")#predict(net,matRWSTest)
#
predictedRWSTest<-data.table(predictedRWSTest)
#
# #predictedRWS[,predictedLabels:=colnames(predictedRWS)[max.col(predictedRWS, ties.method = "first")]]
predictedRWSTest[,fog:=V2>0]
predictedRWSTest[,file:=filesTest]

confusionTest<-data.table(predicted=predictedRWSTest$fog,fogSensor=testing$foggy)

#table(confusionTest$predicted,confusionTest$fogSensor)

confMatrixTest<-confusionMatrix(confusionTest$predicted,confusionTest$fog, mode = "prec_recall", positive = "TRUE")


#draw_confusion_matrix_binary(confMatrixTest)
@




\begin{frame}{Pre-processing and network architecture}
\begin{textblock*}{8cm}(0.2cm,2.5cm)
\begin{center}
\begin{itemize}
\item Pre-processing of images:
\begin{itemize}
\item Scaling to 28x28 px to reduce feature space
\item Image blurring/smoothing to help against overfitting
\end{itemize}
\item Deep Neural Network: L$_{input}$: 2352, L$_1$:800, L$_2$:500, L$_3$:100, L$_{out}$:2
\end{itemize}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(6cm,2.5cm)
\begin{center}
\includegraphics[width=4cm]{private/original1.png}\\
\includegraphics[width=1cm]{private/resize1.png}\\
\includegraphics[width=1cm]{private/blurr1.png}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(0.7cm,5.75cm)
\begin{center}
\includegraphics[width=5cm]{DNN.png}
\end{center}
\end{textblock*}
\end{frame}



\begin{frame}{Evaluation of performance}
\begin{textblock*}{6cm}(0.5cm,2.75cm)
\begin{itemize}
\item Accuracy can be misleading especially in unbalanced datasets like this one.
\item Better to use:
\begin{itemize}
\item Precision: fraction of items selected that are relevant (correct) ($Prec=\frac{TP}{TP+FP}$)
\item Recall: fraction of items correctly selected on all the relevant items  ($Rec=\frac{TP}{TP+FN}$)
\end{itemize}
\end{itemize}
\end{textblock*}
\begin{textblock*}{4.8cm}(7.5cm,2cm)
 \includegraphics[width=4cm]{private/precisionRecall.png}
\end{textblock*}
\end{frame}





\begin{frame}{Results}
\begin{itemize}
\item Results:
\begin{itemize}
\item In-sample:
<<inSampleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
draw_confusion_matrix_binary(confMatrixTraining)
@
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Results (continued)}
\begin{itemize}
\item Results:
\begin{itemize}
\item Out-of-sample:
 <<outOfSamepleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
  draw_confusion_matrix_binary(confMatrixTest)
@
 \end{itemize}
 \end{itemize}
 \end{frame}


\begin{frame}{Next steps}
\begin{itemize}
\item Wait for the foggy period to get more images :-)
\item Manual labelling of the images far from meteo stations (labor intensive, any volunteers??)
\item Get more foggy images for training the network (partners welcome)
% \item Test a more advanced technique for image processing: convolutional neural networks
\item Test with more classes of visibility (initial results)
\item Add meteo-related features
\item Fog at night time (?)
\end{itemize}
\end{frame}
%

% \begin{frame}{Conclusion}
% \begin{itemize}
% \item We are transitioning from a one-scene to \textbf{dynamic-scene} fog recognition
% \item Getting acquainted with new ML techniques (i.e., NN)
% \item Results look \textbf{good} from this last example
% \item \large Architecture for images and metadata handling essential to speed up and automate the analysis process. This aspect does \textbf{NOT} have to be underestimated for data science projects
% \item \normalsize Sometimes I miss Martin Roth! :-)
%
% \end{itemize}
% \end{frame}

\begin{frame}
\begin{textblock*}{8cm}(0.5cm,1.2cm)
\begin{center}
\includegraphics[width=9.3cm]{thanks.jpg}
\end{center}
\end{textblock*}

\begin{textblock*}{8cm}(5.5cm,6.2cm)
\begin{center}
\includegraphics[width=4.3cm]{knmiDataLabLogoMail.png}
\end{center}
\end{textblock*}
\end{frame}
\end{document}

