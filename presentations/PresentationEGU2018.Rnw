\documentclass[10pt,fleqn]{beamer}

\usepackage{lmodern}
\usepackage{knmiBeamer}
\usepackage{multirow}
\usepackage[skins]{tcolorbox}

\Engelstrue     % For English slides 
\renewcommand{\titleFigure}{../figure/fogCover.jpg}

\usepackage{tikz}
\usepackage{verbatim}
\usetikzlibrary{arrows, shapes}

% ---------------
% Graphics folder
% ---------------
\graphicspath{{../figure/}}

\title[Neural network approach for automatic fog detection using surveillance
camera images]
\subtitle{KNMI DataLab Meeting}
\date{September 27, 2017}
\author[Pagani, Roth, Wauben]{G.A. Pagani, J.W. Noteboom\\ and W. Wauben}

\begin{document}
\tikzstyle{every picture}+=[remember picture]


<< Libraries, include=FALSE>>=
library(data.table)
library(imager)
library(visDec)
library(ggplot2)
library(rpart)
library(rattle)
library(rgdal)
library(ggmap)

library(DBI)
library(jsonlite)
library(data.table)
library(caret)
library(darch)


knitr::opts_chunk$set(echo = FALSE, cache = TRUE)

#setwd("~/development/fogDec/")

@

\begin{frame}
 \titlepage
\end{frame}

 \begin{frame}{Outline}
  \begin{itemize}
  \item Motivation for Fog
   \item Purpose
   \item Approach
   \item Results (till Dec 2016)
   \item RWS project phase (since Jan 2017)
   \item New results
   \item Conclusion
 \end{itemize}
 \end{frame}







% \begin{frame}{Fog as hazard}
%  \begin{textblock*}{5cm}(7.4cm,2.4cm)
%   \includegraphics[width=5cm]{Accident.jpeg}
%  \end{textblock*}
%  \begin{textblock*}{5cm}(7.4cm,5.5cm)
%   \includegraphics[width=5cm]{airplane.jpg}
%  \end{textblock*}
% 
% \begin{textblock*}{7cm}(0.2cm,3cm)
% \begin{itemize}
%   \item Substantial impact on air, marine, and road traffic
%   \item Loss of life comparable to that of tornadoes or even winter storms\footnote{Gultepe, I. et al. (2007): Fog research: A review of past achievements and future perspectives. \emph{Pure and Applied Geophysics}, \textbf{164}, 1121--1159.}
%   \item May form and dissipate suddenly
%   \item Often only a local phenomenon
%   \item Not easy to accurately forecast
%   \item Satellites are not pointing to NL 24/7
%   \item But maybe other ubiquitous ``sensors'' can be used e.g., traffic cameras
%  \end{itemize}
%   \end{textblock*}
% \end{frame}
% 
% 
% \begin{frame}{Purpose, Scope, Benefits of the project}
% \begin{itemize}
% \item \textbf{Purpose:} use cameras to identify fog conditions to issue safety hazards
% \item \textbf{Scope:} daylight fog identification from static scenery cameras using image analysis
% \item \textbf{Benefits:}
% \begin{itemize}
% \item \textit{Society: }
% \begin{itemize}
% \item human lives
% \item economic
% \end{itemize}
% \item \textit{KNMI:}
% \begin{itemize}
% \item better widespread observations of fog conditions
% \item feed the fog observations in KNMI models (re-analysis) $\Rightarrow$ better fog modeling/predictions
% \end{itemize}
% \end{itemize}
% 
% \end{itemize}
% \end{frame}
% 
% \begin{frame}{Approach: availability of sensors and traffic cameras}
%  \begin{textblock*}{5cm}(1.2cm,3.0cm)
%   \includegraphics[width=5cm]{SensorPlacement.png}
%  \end{textblock*}
%  \begin{textblock*}{5cm}(7.0cm,3.7cm)
%   \includegraphics[width=5cm]{CameraPlacement.jpg}
%  \end{textblock*}
% \end{frame}
% 
% \begin{frame}{Data sets}
% \begin{columns}
% \column{0.6\textwidth}
% \begin{itemize}
% \item 2 KNMI stations: 3 cameras
% \item 4 Dutch airports: 7 cameras
% \item 160 cameras along A15-A16-A4-A5-A1-A9-A50-A12-A27-A2 NL highways
% \item ~7 million images archived
% \item ~1.5 million labeled
% \end{itemize}
% \column{0.4\textwidth}
%    \includegraphics[width=4.5cm]{schiphol.jpg}
%    \vspace*{0.2cm}
%   \includegraphics[width=4.5cm]{camerasRWS.png}
% \end{columns}
% 
% \end{frame}
% 
% 
% 
% \begin{frame}{Approach: Neural Network (in a nutshell)}
% \begin{textblock*}{8cm}(0.5cm,2.2cm)
% \begin{itemize}
% \item Inspired by the functioning and firing of neurons in the brain
% \item Allow the fitting of complex non-linear classification tasks
% \item With many input high order interaction terms would explode (e.g., 25x25px gray-scale image and we want quadratic interaction terms requires 3 millions features)
% \item Used proficiently in image processing and image classification
% \item Training to find the right weights can be long if networks are big and deep
% \item Activation function can be customized (usually sigmoid-like function)
% \end{itemize}
% \end{textblock*}
% \begin{textblock*}{8cm}(6.5cm,3cm)
% \begin{center}
% \includegraphics[width=3cm]{nnet.png}\\
% \includegraphics[width=3cm]{artificial.jpg}
% \end{center}
% \end{textblock*}
% \end{frame}
% 
% 
% \begin{frame}{Why NN}
% \begin{textblock*}{9.5cm}(0.1cm,2.2cm)
% \begin{itemize}
% \item New more general idea of fog detection then our previous attempt with decision trees and picture features
% \item Reason: scenery are too different also for the same camera (e.g., zoom)
% \end{itemize}
% \end{textblock*}
% \begin{textblock*}{8cm}(7.5cm,2.2cm)
% \begin{center}
% \includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170801_0502.jpg}\\
% \includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1232.jpg}\\
% \includegraphics[width=2.3cm]{private/A4-HM81-ID11066_20170802_1242.jpg}
% \end{center}
% \end{textblock*}
% \begin{textblock*}{9.5cm}(0.1cm,3.5cm)
% \begin{itemize}
% \item Features is the whole picture: each pixel (of each of the RGB layers)
% \item Use a deep neural network (InputL:2352,L1:800,L2:500,L3:100,L5:10,OutputL:2) to fit the model
% \item Training set: +-750 random fog and +-750 non-fog pictures from De Bilt, Cabauw, Airports, A4 HM50-HM110 (i.e.,9 cameras)
% \item Labels: from forward scatter visibility sensor that provides mteorological optical range (MOR)
% \item Fog considered if visibility $\leq$250m
% \begin{itemize}
% \item NB: labels in for highway cameras are given by a KNMI station in a radius of 7.5km
% \end{itemize}
% \end{itemize}
% \end{textblock*}
% \end{frame}
% 
% 
% <<NN highways, echo=FALSE>>=
% #results for presentation
% 
% 
% modelDarch<-readRDS("~/development/fogNNmodels/model1.rds")
% dataMatTrain<-readRDS("~/development/fogNNmodels/trainingDataMat.RDS")
% dataMatTest<-readRDS("~/development/fogNNmodels/testingDataMat.RDS")
% 
% testing<-readRDS("~/development/fogNNmodels/testingDataLabels.RDS")
% training<-readRDS("~/development/fogNNmodels/trainingDataLabels.RDS")
% 
% filesTest<-readRDS("~/development/fogNNmodels/filenamesTest.RDS")
% files<-readRDS("~/development/fogNNmodels/trainingFileNames.RDS")
% 
% 
% dtMat<-data.table(dataMatTrain)
% #dtMat[,vis_class:=res2$vis_class]
% dtMat[,foggy:=training$foggy]
% 
% 
% ###In sample testing#####
% predictedRWS<-predict(modelDarch,dataMatTrain, type = "bin")
% #predict(net,matRWS)
% #
% predictedRWS<-data.table(predictedRWS)
% #
% # #predictedRWS[,predictedLabels:=colnames(predictedRWS)[max.col(predictedRWS, ties.method = "first")]]
% predictedRWS[,fog:=V2>0]
% predictedRWS[,file:=files]
% 
% 
% 
% confusion<-data.table(predicted=predictedRWS$fog,fogSensor=dtMat$foggy)
% 
% #table(confusion$predicted,confusion$fogSensor)
% 
% confInSample<-confusionMatrix(confusion$predicted,confusion$fog, mode = "prec_recall", positive = "TRUE")
% 
% 
% 
% 
% ####OUT of sample testing##
% predictedRWSTest<-predict(modelDarch,dataMatTest, type = "bin")#predict(net,matRWSTest)
% #
% predictedRWSTest<-data.table(predictedRWSTest)
% #
% # #predictedRWS[,predictedLabels:=colnames(predictedRWS)[max.col(predictedRWS, ties.method = "first")]]
% predictedRWSTest[,fog:=V2>0]
% predictedRWSTest[,file:=filesTest]
% 
% 
% 
% confusionTest<-data.table(predicted=predictedRWSTest$fog,fogSensor=testing$foggy)
% 
% #table(confusionTest$predicted,confusionTest$fogSensor)
% 
% confOutSample<-confusionMatrix(confusionTest$predicted,confusionTest$fog, mode = "prec_recall", positive = "TRUE")
% 
% 
% @
% 
% % 
% 
% <<confusionDraw, echo=FALSE>>=
% 
% draw_confusion_matrix <- function(cm) {
% 
%   layout(matrix(c(1,1,2)))
%   par(mar=c(2,2,2,2))
%   plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
%   title('CONFUSION MATRIX', cex.main=2)
% 
%   # create the matrix
%   rect(150, 430, 240, 370, col='#3F97D0')
%   text(195, 435, 'FALSE', cex=1.2)
%   rect(250, 430, 340, 370, col='#F7AD50')
%   text(295, 435, 'TRUE', cex=1.2)
%   text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
%   text(245, 450, 'Actual', cex=1.3, font=2)
%   rect(150, 305, 240, 365, col='#F7AD50')
%   rect(250, 305, 340, 365, col='#3F97D0')
%   text(140, 400, 'FALSE', cex=1.2, srt=90)
%   text(140, 335, 'TRUE', cex=1.2, srt=90)
% 
%   # add in the cm results
%   res <- as.numeric(cm$table)
%   text(195, 400, res[1], cex=1.6, font=2, col='white')
%   text(195, 335, res[2], cex=1.6, font=2, col='white')
%   text(295, 400, res[3], cex=1.6, font=2, col='white')
%   text(295, 335, res[4], cex=1.6, font=2, col='white')
% 
%   # add in the specifics
%   plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
%   text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
%   text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
%   text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
%   text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
%   text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
%   text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
%   text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
%   text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
%   text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
%   text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
% 
%   # add in the accuracy information
%   text(50, 35, names(cm$overall[1]), cex=1.5, font=2)
%   text(50, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
%   #text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
%   #text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
% }
% @
% 
% 
% 
% \begin{frame}{New Results (new continued)}
% \begin{textblock*}{8cm}(0.2cm,3.5cm)
% \begin{center}
% \begin{itemize}
% \item Test set: 4000 random non-fog images, 334 foggy images (not part of training set, obviously)
% \item Pre-processing of images:
% \begin{itemize}
% \item Scaling to 28x28 px to reduce feature space
% \item Image blurring/smoothing to help against overfitting
% \end{itemize}
% \end{itemize}
% \end{center}
% \end{textblock*}
% 
% \begin{textblock*}{8cm}(6cm,2.5cm)
% \begin{center}
% \includegraphics[width=4cm]{private/original1.png}\\
% \includegraphics[width=1cm]{private/resize1.png}\\
% \includegraphics[width=1cm]{private/blurr1.png}
% \end{center}
% \end{textblock*}
% \end{frame}
% 
% \begin{frame}{New Results (new continued)}
% \begin{itemize}
% \item Results:
% \begin{itemize}
% \item In-sample:
% <<inSampleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
% draw_confusion_matrix(confInSample)
% @
% \end{itemize}
% \end{itemize}
% \end{frame}
% 
%  \begin{frame}{New Results (new continued)}
%  \begin{itemize}
% \item Results:
%  \begin{itemize}
%  \item Out-of-sample:
%  <<outOfSamepleConfusion, echo=FALSE, fig.height=4, fig.width=7>>=
%  draw_confusion_matrix(confOutSample)
%  @
% 
%  \end{itemize}
%  \end{itemize}
% 
%  \end{frame}
% 
% % 
% \begin{frame}{Next steps: many!}
% \begin{itemize}
% \item Wait for the foggy period to get more images :-)
% \item Test the approach on other highways and manually examine the labels (labor intensive, any volunteers??)
% \item Get more for images for training the network from UK MetOffice (contacts at EGU2017)
% \item Test a more advanced technique for image processing: convolutional neural networks
% \item Test with more classes of visibility
% \item Fog at night time (?)
% \item Add meteo-related features
% \end{itemize}
% \end{frame}
% 
% 
% \begin{frame}{Conclusion}
% \begin{itemize}
% \item We are transitioning from a one-scene to \textbf{dynamic-scene} fog recognition
% \item Getting acquainted with new ML techniques (i.e., NN)
% \item Results look \textbf{good} from this last example
% \item \large Architecture for images and metadata handling essential to speed up and automate the analysis process. This aspect does \textbf{NOT} have to be underestimated for data science projects
% \item \normalsize Sometimes I miss Martin Roth! :-)
% 
% \end{itemize}
% \end{frame}


\end{document}